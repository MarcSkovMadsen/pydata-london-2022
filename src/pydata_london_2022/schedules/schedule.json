
{"schedule": {"version": "0.19", "base_url": "https://london2022.pydata.org/cfp/schedule/", "conference": {"acronym": "cfp", "title": "PyData London 2022", "start": "2022-06-17", "end": "2022-06-19", "daysCount": 3, "timeslot_duration": "00:05", "rooms": [{"name": "Tower Suite 1", "guid": null, "description": null, "capacity": null}, {"name": "Tower Suite 2", "guid": null, "description": null, "capacity": null}, {"name": "Tower Suite 3", "guid": null, "description": null, "capacity": null}, {"name": "Beaufort", "guid": null, "description": null, "capacity": null}], "days": [{"index": 1, "date": "2022-06-17", "day_start": "2022-06-17T04:00:00+01:00", "day_end": "2022-06-18T03:59:00+01:00", "rooms": {"Tower Suite 1": [{"id": 41, "guid": "deecd709-9583-5f7f-a3b5-8b954a957492", "logo": "", "date": "2022-06-17T09:00:00+01:00", "start": "09:00", "duration": "01:30", "room": "Tower Suite 1", "slug": "cfp-41-sktime-python-toolbox-for-time-series-how-to-implement-your-own-estimator", "url": "https://london2022.pydata.org/cfp/talk/AHH8FE/", "title": "sktime - python toolbox for time series: how to implement your own estimator", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "sktime is a widely used scikit-learn compatible library for learning with time series. sktime is easily extensible by anyone, and interoperable with the pydata/numfocus stack. This tutorial explains how to write your own sktime estimator, e.g., forecaster, classifier, transformer, by using sktime\u2019s extension templates and testing framework. A custom estimator can live in any local code base, and will be compatible with sktime pipelines, or scikit-learn. A continuation of the sktime introductory tutorial at pydata [link]", "description": "Writing sktime compatible estimators is meant to be easy.\r\n\r\nThis tutorial will explain: \u2022 sktime base class and estimator architecture \u2022 basic software design patterns used in extension \u2022 how to use the extension templates \u2022 how to validate your custom estimator \u2022 testing in third party extensions and packages\r\n\r\nUsers can write sktime compatible estimators without a full developer setup, or any need to contribute the estimator to the sktime codebase. The custom estimator can be used with any tuning, pipeline, composition, or reduction functionality in sktime, and will be compatible with scikit-learn, too. This philosophy enables interoperability with third projects, proprietary code bases, or custom extension packages to sktime.\r\n\r\nHow this works technically: sktime ensures that all estimators of a certain type, e.g., forecasters, adhere to the same interface contracts, by using the base class and strategy patterns.\r\n\r\nSeparate to this user sided contract is the extension contract, which \"extenders\", users implementing their own estimators, have to satisfy. This is based on the template pattern which keeps boilerplate from the extension contract, and clearly defined \"fill in your code\" instructions in sktime\u00b4s extension templates.\r\n\r\nThe extension templates are python files with gaps that the extender is meant to fill in with the logic of a new estimator, with clear instructions in comments, and without any boilerplate. Finally, the sktime test suite provides few-line-validation for any custom estimator.\r\n\r\nA full developer setup is typically not required to implement a custom estimator compatible with sktime.", "recording_license": "", "do_not_record": false, "persons": [{"id": 107, "code": "8VM8ME", "public_name": "Franz Kiraly", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 68, "guid": "b883eccf-8e31-5e61-b7b1-c73f20459452", "logo": "", "date": "2022-06-17T11:00:00+01:00", "start": "11:00", "duration": "01:30", "room": "Tower Suite 1", "slug": "cfp-68-train-object-detection-with-small-datasets", "url": "https://london2022.pydata.org/cfp/talk/DXNSZA/", "title": "Train Object Detection with small Datasets", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "Object detection, the task of localising and classifying objects in a scene, one of the most popular tasks in Computer Vision, has a main drawback: a large annotated dataset is necessary to train the model. Indeed, annotating a dataset is expensive, and the free available datasets are not enough, as they do not contain all the classes we are interested in. Thus, the goal of the tutorial is to introduce the main techniques to train a good object detector utilising the minimum amount of annotated data.", "description": "The goals of the tutorial can be summarised in the following points: 1. Introduce deep learning-based object detector models. 2. Show the power of transfer learning: few new data are necessary if the model has been pretrained on a large dataset. 3. Define the properties of a good dataset (i.e., maximal entropy), and describe how to obtain it. The tutorial is for those interested in deep and transfer learning or who want to learn more about it. No prior knowledge of computer vision is required.", "recording_license": "", "do_not_record": false, "persons": [{"id": 109, "code": "EAWWKP", "public_name": "vincenzo crescimanna", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 196, "guid": "833470e2-bf73-57db-86b6-8d639ee05358", "logo": "", "date": "2022-06-17T13:30:00+01:00", "start": "13:30", "duration": "01:30", "room": "Tower Suite 1", "slug": "cfp-196-introducing-more-of-the-standard-library", "url": "https://london2022.pydata.org/cfp/talk/3FCNCC/", "title": "Introducing more of the standard library", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "For novice Python users who want to learn about some of the helpful modules that come in the python standard library. In particular we will talk about `pathlib`, `datetime`, `collections`, `itertools`, and `functools`! Please come with Jupyter Notebook installed.", "description": "Python comes with many standard library packages included without any \"pip install\"! In this beginners tutorial we will go through a few of these with some interactive challenges during the session. Specifically we will dive into `pathlib`, `datetime`, `collections`, `itertools` and `functools` and how these can help you.\r\n\r\nYou should come away understanding the key features of each of these packages and how to use them in you next project.\r\n\r\nPlease come with Jupyter Notebook installed. If you're using conda do `conda install jupyter`.\r\n\r\nRepository link: https://github.com/simonwardjones/pydata-talk-2022", "recording_license": "", "do_not_record": false, "persons": [{"id": 117, "code": "XVSYJP", "public_name": "Simon Ward-Jones", "biography": "Simon is a Senior Data Scientist at Deliveroo with 8 years experience in Retail and Tech. He is interested in many areas of data science having worked in machine learning, causal inference as well as experimentation design and statistics.\r\n\r\nHe is from Berkhamsted in the UK, studied maths in Oxford and now lives and works in London.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 143, "guid": "ba801637-fe87-5902-94d1-e711ca238b84", "logo": "", "date": "2022-06-17T15:30:00+01:00", "start": "15:30", "duration": "01:30", "room": "Tower Suite 1", "slug": "cfp-143-how-to-stack-neural-networks-together-ideas-and-applications", "url": "https://london2022.pydata.org/cfp/talk/QL9GCD/", "title": "How to Stack Neural Networks together ? Ideas and Applications", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "Exploring the process, implementation, practical applications, and advantages of stacking neural networks together. The tutorial focuses on building tunable, high-performance, multi-data-type feature models seamlessly using network concatenations in TensorFlow. We implement 3 examples and also derive explainability for a stacked neural network.", "description": "Stacking different Neural Nets together is extremely beneficial for applications that involve the availability of different data types ( Images + Text + Tabular ) to make better decisions. In this tutorial, we will find answers to fundamental questions behind stacking: Why stack? How to stack? Train - individually / together? Number of models? Hyperparameter tuning? Stacking pre-trained models? Accessing models post stacked training and very importantly, explainability? and consequently, implement Stacking for 3 use cases - Multi Data Type, Pretrained Model, Restricted Neural Nets.", "recording_license": "", "do_not_record": false, "persons": [{"id": 71, "code": "CVJAJX", "public_name": "Pranjal Biyani", "biography": "Pranjal is an experienced AI Scientist building the first AI powered platform to accelerate R&D for Material Sciences across the globe. He loves opening black-box models to reveal insightful AI secrets that help decision makers adapt with the ever changing Industry needs. He also loves to teach and mentor passionate individuals aspiring to be a part of the Data Science Community, all with his favourite language, Python!", "answers": []}], "links": [], "attachments": [], "answers": []}], "Tower Suite 2": [{"id": 79, "guid": "d2a11e03-7bff-5968-86c0-e26e7bb62ff7", "logo": "", "date": "2022-06-17T09:00:00+01:00", "start": "09:00", "duration": "01:30", "room": "Tower Suite 2", "slug": "cfp-79-data-validation-for-data-science", "url": "https://london2022.pydata.org/cfp/talk/FLXATN/", "title": "Data Validation for Data Science", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "Have you ever worked really hard on choosing the best algorithm, tuned the parameters to perfection, and built awesome feature engineering methods only to have everything break because of a null value? Then this tutorial is for you! Data validation is often neglected in the process of working on data science projects. In this tutorial, we will demonstrate the importance of implementing data validation for data science in commercial, open-source, and even hobby projects. We will then dive into some of the open-source tools available for validating data in Python and learn how to use them so that edge cases will never break our models. The open-source Python community will come to our help and we will explore wonderful packages such as Pydantic for defining data models, Pandera for complementing the use of Pandas, and Great Expectations for diving deep into the data. This tutorial will benefit anyone working on data projects in Python who want to learn about data validation. Some Python programming experience and understanding of data science are required. The examples used and the context of the discussion is around data science, but the knowledge can be implemented in any Python oriented project.", "description": "For this tutorial, you will need a working Python environment with Jupyter installed, or just a web browser and a Google account for using Google Colab. We will go through the hands-on exercises together in Jupyter notebooks. The context of the tutorial is a standard data science project with the common practice architecture of data ingestion, feature engineering, model training, model serving, etc. In the first part of the tutorial, we will go through all of the common pitfalls where unexpected data values can impact the model performance, or even worse - break the run altogether. In light of the potential consequences, we will discuss the importance of data validation. For the second part of the tutorial we will dive into some of the open-sourced tools in the Python community that can help us with the validation task: Pydantic - For defining data models, types, and simple checks. Pandera - Used on top of Pandas Dataframes for schema validation. Great Expectations - a framework for data testing, quality, and profiling.\r\nAll the materials and notebooks needed can be found in this repository: https://github.com/NatanMish/data_validation", "recording_license": "", "do_not_record": false, "persons": [{"id": 99, "code": "9CTDPX", "public_name": "Natan Mish", "biography": "Senior Machine Learning Engineer at Zimmer Biomet. London School of Economics graduate with an MSc in Applied Social Data Science. Passionate about using Machine Learning to solve complicated problems. I have experience analysing and researching data in the financial, real estate, transportation and healthcare industries. Curious about (almost) everything and always happy to take on new experiences and challenges. I love finding bugs, especially if they're my own making!", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 117, "guid": "7a579b14-84ef-5f9f-8f19-c9577ee59ed7", "logo": "", "date": "2022-06-17T11:00:00+01:00", "start": "11:00", "duration": "01:30", "room": "Tower Suite 2", "slug": "cfp-117-feature-engineering-made-simple", "url": "https://london2022.pydata.org/cfp/talk/LJFCWX/", "title": "Feature Engineering Made Simple", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "Of all the choices made by data scientists in the course of building and operating models, feature engineering & selection is one of the most critical. Features have a substantive impact on a model\u2019s quality, including its predictive accuracy and resilience. Unfortunately, as most ML scientists and practitioners are aware, feature engineering is more art than science. It is ad-hoc, messy, error-prone and ends up consuming 70-80% of the time and effort when building models, often resulting in sub-optimal feature selection leading to low-quality models. In this tutorial, we will introduce new ways of performing feature engineering, turning it into a systematic, procedural and scalable process, which is substantively more efficient than how it occurs currently. Participants will perform a hands-on, end-to-end, feature building exercise, with particular emphasis on feature engineering using Anovos (https://anovos.ai/ or https://github.com/anovos/anovos)", "description": "Of all the choices made by data scientists in the course of building and operating models, feature selection is one of the most critical. Features have a substantive impact on a model\u2019s quality, including its predictive accuracy and resilience. Therefore, feature engineering is one of the most important components of the Machine Learning workflow.\r\n\r\nUnfortunately, as most ML scientists and practitioners are aware, Feature Engineering is more art than science. It is ad-hoc, messy, terribly error-prone and ends up consuming 70-80% of the effort and time when building models, often resulting in sub-optimal feature selection leading to low-quality models.\r\n\r\nWhile there are a host of tools, mostly open-source, that help with parts of the feature engineering process, in particular in performing exploratory data analysis (EDA), their impact is modest: 1. The biggest problem in feature engineering is task orchestration \u2013 methodically performing a set of steps leading up to a set of \u201cgood\u201d, model-ready features. Existing tools, such as PANDAS based packages, enable the performance of individual tasks (e.g., outlier detection) but the act of systematic orchestration is still totally left up to the modeller, and usually leads to a very ad-hoc, trial-and-error feature engineering workflow. 2. There are a few key problems in feature engineering that have no packaged solutions at all. One such problem is \u201ccold-start\u201d \u2013 when starting to select candidate features, what should the modeller do? The entire space of possible features for a given problem is usually very large, so a small subset needs to be identified for investigation \u2013 suboptimal candidate feature selection is usually very detrimental. This is one of the hardest issues in feature engineering. 3. Finally, virtually every open-source library is scale challenged, performing the in-memory computation in a single thread. When the base data has a meaningful scale, these are simply impractical to use.\r\n\r\nIn this tutorial, we will introduce new ways of performing feature engineering, turning it into a systematic, procedural and scalable process, which is substantively more efficient than how it occurs currently. Participants will perform a hands-on, end-to-end, model building exercise, with particular emphasis on feature engineering using Anovos (https://anovos.ai/ or https://github.com/anovos/anovos).\r\n\r\nAnovos is a fast-growing open-source library built by data scientists at Mobilewalla with years of experience in applying Machine Learning techniques to some of the most extensive consumer data sets available. By rethinking ingestion and transformation, and including deeper analytics, drift identification, and stability analysis, Anovos aims to improve productivity and helps data scientists build more resilient, higher performing models. In addition, it automatically produces easily interpretable professional data reports that help users understand the nature of data at first sight and further enable data scientists to identify and engineer features.", "recording_license": "", "do_not_record": false, "persons": [{"id": 47, "code": "DBFZ7Z", "public_name": "Kajanan Sangaralingam", "biography": "Head of Data Science, Mobilewalla\r\n\r\nKajanan Sangaralingam manages the Data Science and AI function at Mobilewalla. He is passionate about solving real business problems using innovative AI/machine learning approaches. Prior to Mobilewalla, Kajanan worked as a Senior Data Scientist at Singapore Telecommunications where he honed his skills processing and analyzing large volumes of structured and unstructured data. He earned his Ph.D. at the National University of Singapore and his Bachelor of Science in Information Technology degree at the University of Moratuwa, Sri Lanka. His early work experience included many roles as a Senior Software Engineer and Software Engineer at companies in various industries.", "answers": []}, {"id": 132, "code": "L7GAVP", "public_name": "Anindya Datta", "biography": "Founder & CEO, Mobilewalla\r\nAnindya Datta is a leading technologist and innovator with core contributions in best-in-class large-scale data management solutions, artificial intelligence, and internet technologies. As Founder, CEO, and Chairman of Mobilewalla, Anindya has combined the industry\u2019s most robust data set with deep artificial intelligence and data science expertise to help enterprises build high performing, resilient predictive models.\r\n \r\nPrior to Mobilewalla, Anindya founded Chutney Technologies which was acquired by Cisco Systems in 2005. He has been on the faculties of major research universities and institutes in the United States and abroad, including the Georgia Institute of Technology, University of Arizona, National University of Singapore, and Bell Laboratories. Anindya obtained his undergraduate degree from the Indian Institute of Technology (IIT) Kharagpur, and his MS and Ph.D. degrees from the University of Maryland, College Park, USA.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 159, "guid": "fccc0b14-2f72-5d2e-9153-e6d9e76de415", "logo": "", "date": "2022-06-17T13:30:00+01:00", "start": "13:30", "duration": "01:30", "room": "Tower Suite 2", "slug": "cfp-159-data-science-at-scale-with-dask", "url": "https://london2022.pydata.org/cfp/talk/TWTUFD/", "title": "Data Science at Scale with Dask", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "This tutorial is an introduction to Dask, an OSS Python library for distributed computing. We will walk through the many ways you can apply Dask to scale your Python code to work with larger datasets and/or transcend other compute-bound limitations.\r\n\r\nThe tutorial will cover: \r\n- how to scale pandas with Dask\r\n- how to scale NumPy with Dask\r\n- how to parallelise your existing Python code with Dask\r\n- how to scale to the cloud with Dask and Coiled\r\n\r\n\r\n\r\nThe tutorial assumes no prior knowledge of Dask.", "description": "An introduction to distributed computing:\r\n\r\nWhen, why and how should you leverage distributed computing?\r\n- Introduction to Dask, an OSS Python library for distributed computing\r\n- How to parallelise your Python code with Dask:\r\n\r\nWhy parallelise your code?\r\n- Using dask.delayed() to parallelise custom code\r\n- Scaling your NumPy and pandas workflows:\r\n\r\nHow to scale your NumPy and pandas to larger-than-memory datasets?\r\n- Dask Collections: Bags, Arrays and DataFrames\r\n- Distributed Machine Learning with Dask:\r\n\r\nHow to build distributed ML models\r\n- Bursting to the cloud to transcend local compute resources", "recording_license": "", "do_not_record": false, "persons": [{"id": 74, "code": "Z3CQNN", "public_name": "Richard Pelgrim", "biography": "Richard Pelgrim is a data scientist with a passion for communicating technical content in creative and compelling ways. Currently he does so as Developer Advocate at Coiled.io, the leading company built around the open-source Dask library for distributed computing in Python. Richard is regularly invited to give Dask tutorials at meet-ups and conferences and has a treasure chest of expert tips to support anyone looking to take their distributed computing to the next level.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 91, "guid": "77bf71d2-6c25-5c0a-bbde-0f359657c5df", "logo": "", "date": "2022-06-17T15:30:00+01:00", "start": "15:30", "duration": "01:30", "room": "Tower Suite 2", "slug": "cfp-91-parallelism-the-old-way-using-mpi-in-python-with-mpi4py", "url": "https://london2022.pydata.org/cfp/talk/HH7SUG/", "title": "Parallelism the Old Way: Using MPI in Python with mpi4py", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "MPI is one of the oldest best-established and best-tested approaches to parallel computing, with bindings for most languages and availability on most systems. MPI uses explicit message passing and can be used on \"shared-nothing\" systems (in which each process/processor has its own memory, unavailable to other processors) as well as shared-memory systems, (uniform and non-uniform).\nThis tutorial will provide a gentle introduction to parallel computing using specifically MPI using the Python mpi4py library.", "description": "There are many different approaches to parallel computing available in Python, many of which are hampered by the global interpreter lock (the GIL). Rather than focusing on threads (for concurrency) or the multiprocessing module (for process-based parallelism) from the standard library, this tutorial will introduce MPI, the Message-Passing Interface, which is the most widely used and successful approach to parallel computing across all languages and systems.\n\nUsing the mpi4py module, the tutorial will introduce parallel computing, explain the difference between multi-threading and parallelism, briefly explain the GIL, and then introduce the well-established, cross-language approach using MPI through the mpi4py module, which by-passes the GIL.\n\nThe tutorial will guide participants through a from-scratch construction of a task farm using MPI.", "recording_license": "", "do_not_record": false, "persons": [{"id": 66, "code": "P8BFTZ", "public_name": "Nick Radcliffe", "biography": "Nick Radcliffe is a data scientist. He runs the consulting and software company, [Stochastic Solutions](https://stochasticsolutions.com), which produces the [Mir\u00f3](https://stochasticsolutions.com/miro/), a commercial data analysis suite, and the open source Python [TDDA](https://pypi.org/project/tdda/) [Library](https://github.com/tdda/tdda) for [test-driven data analysis](https://tdda.info). He is also a Visiting Professor in the [Department of Maths at Univeristy of Edinbugh](https://www.maths.ed.ac.uk), and is acting Chief Data Scientist at [Smart Data Foundry](https://smartdatafoundry.com).\r\n\r\nNick has a background in parallel & high-performance computing from his time at [EPCC](https://www.epcc.ed.ac.uk).", "answers": []}], "links": [], "attachments": [], "answers": []}], "Tower Suite 3": [{"id": 44, "guid": "ab41742b-8f74-5eec-ab5d-38456ea82a50", "logo": "", "date": "2022-06-17T09:00:00+01:00", "start": "09:00", "duration": "01:30", "room": "Tower Suite 3", "slug": "cfp-44-sqlalchemy-and-you-making-sql-the-best-thing-since-sliced-bread", "url": "https://london2022.pydata.org/cfp/talk/ANH9GU/", "title": "SQLAlchemy and you - making SQL the best thing since sliced bread", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "Are you writing SQL strings in your code? Have you only used ORMs and want to start getting more control over your SQL?\r\n\r\nSQLAlchemy is the gold-standard for working with SQL in Python and this tutorial will get you comfortable with working in it so you can take advantage of its power. We will go through Core and ORM abstractions so you'll be comfortable navigating through the different layers and be able to fully use the power of Python when writing your SQL", "description": "SQLAlchemy has been the defacto SQL toolkit in Python for a very long time - providing great abstractions, a powerful ORM but built on a flexible Core.\r\n\r\nIn this tutorial, we will go through SQLAlchemy's Core and ORM layers, giving you an introduction to what they are capable of and showing off the many clever features available to us when we're able to write SQL in pure Python.\r\n\r\nWe'll discuss common pitfalls and tips I've learned from my many years of using SQLAlchemy and you'll walk away with a good understanding of what SQLAlchemy is capable of and able to implement them in your own codebases\r\n\r\nSome knowledge of SQL is expected - if you know what a JOIN and a GROUPBY are, you're good to go!\r\n\r\nIf you want to code alongside, an installation of Docker or Postgres is helpful, although instructions are available if you want to avoid these extra dependencies", "recording_license": "", "do_not_record": false, "persons": [{"id": 18, "code": "SGUSYK", "public_name": "Anders Bogsnes", "biography": "I'm the Head of the Python Enablement Team at Nordea Asset Manager, driving enablement and adoption of Python for our teams. \r\n\r\nI've previously worked as a tech lead for ML and Analytics, Sales Analytics as well as a Business Analyst and Management Advisor.\r\n\r\nI also organize the Pydata Copenhagen monthly meetup", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 2, "guid": "967e1827-8529-53ec-ae25-5569fb76274e", "logo": "/media/cfp/submissions/HHNVCM/PyMC_FfJjP39_vdKwpFF.png", "date": "2022-06-17T11:00:00+01:00", "start": "11:00", "duration": "01:30", "room": "Tower Suite 3", "slug": "cfp-2-probabilistic-python-an-introduction-to-bayesian-modeling-with-pymc", "url": "https://london2022.pydata.org/cfp/talk/3YXZVP/", "title": "Probabilistic Python: An Introduction to Bayesian Modeling with PyMC", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "Bayesian statistical methods offer a powerful set of tools to tackle a wide variety of data science problems. In addition, the Bayesian approach generates results that are easy to interpret and automatically account for uncertainty in quantities that we wish to estimate and predict. Historically, computational challenges have been a barrier, particularly to new users, but there now exists a mature set of probabilistic programming tools that are both capable and easy to learn. We will use the newest release of PyMC (version 4) in this tutorial, but the concepts and approaches that will be taught are portable to any probabilistic programming framework.\n\nThis tutorial is intended for practicing and aspiring data scientists and analysts looking to learn how to apply Bayesian statistics and probabilistic programming to their work. It will provide learners with a high-level understanding of Bayesian statistical methods and their potential for use in a variety of applications. They will also gain hands-on experience with applying these methods using PyMC, specifically including the specification, fitting and checking of models applied to a couple of real-world datasets.\n\nAs this is an introductory tutorial, no direct experience with PyMC or Bayesian statistics will be required. However, to benefit maximally from the tutorial, learners should have some familiarity with basic statistics (things like regression and estimation) and with core components of the scientific Python stack (*e.g.* NumPy, pandas and Jupyter).", "description": "This tutorial will be presented with Jupyter notebooks, allowing participants to run examples and exercises on their own computers. A GitHub repository will be set up 2 weeks prior to the PyData London, with instructions on how to set up the Python environment to run the tutorial locally.\n\nAs the goal of the tutorial is to get new users up and running with Bayesian methods, the content will be light on theory and focus on the implementation of models, though some statistical background will be provided for context and clarity. Since PyMC is a high-level statistical package, it is easy to gloss over important details of the underlying algorihtms. Therefore, the tutorial will begin by solving a simple model using only NumPy and SciPy functions before diving into PyMC. As a capstone to the tutorial, learners will be introduced to \"The Bayesian Workflow\" to reiterate the important steps in the process, along with useful tips and tricks.\n\n### Outline\n\n- The basics of Bayes (10 min)\n  - Bayesian intuition\n  - What is a probabilistic model?\n  - Solving a simple model without specialized software\n- Building models in PyMC (20 min)\n  - Picking prior distributions\n  - The data-generating model\n  - Transformed variables\n- Estimating models with Markov chain Monte Carlo (25 min) \n  - How can we estimate a model with sampling?\n  - The Hamiltonian Monte Carlo algorithm\n  - MCMC in PyMC\n  - What to do when things go wrong\n- Model checking (15 min)\n  - Summarizing your model with plots and tables\n  - Did our inference algorithm work as expected\n  - Is our model generating reasonable and believable results?\n- The Bayesian workflow (20 min)\n  - A complete working example, from data import through to interpreting the results", "recording_license": "", "do_not_record": false, "persons": [{"id": 5, "code": "Z3UE7X", "public_name": "Chris Fonnesbeck", "biography": "Chris is the Principal Quantitative Analyst in Baseball Research & Development for the Philadelphia Phillies. He is interested in computational statistics, machine learning, Bayesian methods, and applied decision analysis. He hails from Vancouver, Canada and received his Ph.D. from the University of Georgia.\u200b", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 123, "guid": "76e7eecf-44de-552d-895c-885a11b6e895", "logo": "", "date": "2022-06-17T13:30:00+01:00", "start": "13:30", "duration": "01:30", "room": "Tower Suite 3", "slug": "cfp-123-picking-what-to-watch-next-build-a-recommendation-system", "url": "https://london2022.pydata.org/cfp/talk/LWUK73/", "title": "Picking What to Watch Next - build a recommendation system", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "Recommendation algorithms are the driving force of many businesses: e-commerce, personalized advertisement, on-demand entertainment. Computer algorithms know what you like and present you with things that are customized for you. Here we will explore how to do that by building a system ourselves.", "description": "**Get the workshop project repo in advance: https://bit.ly/pydataldn22**\r\n\r\nIn this workshop, we will use MovieLens Datasets to build a very basic recommendation engine. The model will be KNN Item-Based, meaning based on show information, it suggests users who have watched X show a Y show which is similar to that one. While doing it, we will do data transformation with Pandas and Scipy, and train the model with Scikit-learn.\r\n\r\n**For whom is your Workshop**\r\nData Scientist or developers who have no experience in building a recommendation engine and is curious how it can be done. The model we built is in no way good enough to be deployed as a product but would be a very good first model to learn from and get the idea of how machine learning can be used in finding correlations between items.\r\n\r\n**Short Format of your Workshop**\r\nOverview-5 min, Lecture - 20 mins, Breaks - 10 minutes, Hands-on training - 50 mins, Closing - 5 mins\r\n\r\n**Workshop Agenda**\r\nOverview-5 min\r\n\r\nIn this session, we will go through the workshop structure, introduce the steps that we take and the tools that we will be using in the workshop.\r\n\r\nLecture - 20 mins\r\n\r\nIn this session, through slides and presentation, we will go through some knowledge about recommendation engines, what models are available in the market and how they work. We will discuss their advantages and disadvantages and the fundamental theories that work behind the scenes. This will include the model that we are going to build and the more complicated ones that are more commonly used in business.\r\n\r\nBreaks- 10 minutes\r\n\r\nA short break, overrun buffer, answering questions and setup for the hands-on training.\r\n\r\nHands-on training - 40 mins\r\n\r\nAt the start of this session, we will have a look at the project skeleton and look at the functions that we will implement in this workshop. (5 mins)\r\n\r\nThen we will work on the part that transforms the data into a format that is ready to be trained with the KNN model. (20mins)\r\n\r\nAfterwards, we will work on the part that train the KNN model. Here we will run some experiments and play with different parameters, for example, different similarity metrics, in training. (20 mins)\r\n\r\nFinally, we will test our recommender in the CLI. (5mins)\r\n\r\nBonus: we will test our recommender in the browser with PyScript\r\n\r\nClosing - 5 mins\r\n\r\nIn this session, we will wrap up what we learned and suggest further learning materials to those who may want to study further in this topic.\r\n\r\n**What is required from attendees**\r\nA computer with a stable internet connection; Python 3.9 or above and poetry installed; An opened mind and ready to learn something new\r\n\r\n**What Attendees will Learn**\r\nBy the end of the workshop, you will have been built your first recommendation engine. You will be given enough information about how to build a better one and where to study further in you are inspired to be an expert in this field.\r\n\r\n**Course Benefits**\r\nYou will have learned a new skill set that may assist you in your next data science project. You will be inspired to study further to be able to build a better recommendation engine or do your own research on related topics.", "recording_license": "", "do_not_record": false, "persons": [{"id": 23, "code": "Q8G8KR", "public_name": "Cheuk Ting Ho", "biography": "Before working in Developer Relations, Cheuk has been a Data Scientist in various companies which demands high numerical and programmatical skills, especially in Python. To follow her passion for the tech community, now Cheuk is the Developer Relations Lead at TerminusDB - an open-source graph database. Cheuk maintains its Python client and engages with its user community daily.\r\n\r\nBesides her work, Cheuk enjoys talking about Python on personal streaming platform and podcasts. Cheuk has also been a speaker at Universities and various conferences. Besides speaking at conferences, Cheuk also organises events for developers. Conferences that Cheuk has organized include EuroPython (which she is a board member of), PyData Global and Pyjamas Conf. Believing in Tech Diversity and Inclusion, Cheuk constantly organizes workshops and mentored sprints for minority groups. In 2021, Cheuk has become a Python Software Foundation fellow.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 160, "guid": "f83a16de-44ca-510a-8fd7-0eb05daa4c70", "logo": "", "date": "2022-06-17T15:30:00+01:00", "start": "15:30", "duration": "01:30", "room": "Tower Suite 3", "slug": "cfp-160-document-sentence-similarity-solution-using-open-source-nlp-libraries-frameworks-and-datasets", "url": "https://london2022.pydata.org/cfp/talk/TXEZ9X/", "title": "Document/sentence similarity solution using open source NLP libraries, frameworks and datasets", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "The need to develop robust document/text similarity measure solutions is an essential step for building applications such as Recommendation Systems, Search Engines, Information Retrieval Systems including other ML/AI applications such as News Aggregators or Automated Recruitment systems used to match CVs to job specification and so on. In general, text similarity is the measure of how words/tokens, tweets, phrases, sentences, paragraphs and entire documents are lexically and\u202fsemantically close to each other. Texts/words are lexically similar if\u202fthey\u202fhave similar character sequence or structure and, are semantically similar if they have the same meaning, describe similar concepts and they are used in the same context.\u202f\u202f \r\n\r\nThis tutorial will demonstrate a number of strategies for feature extraction i.e., transforming documents to numeric feature vectors. This transformation step is a prerequisite for computing the similarity between documents. Typically, each strategy will involve 4 steps, namely: 1) the use of standard natural language pre-processing techniques to prepare/clean the documents, 2) the transformation of the document text into numeric vectors/embeddings, 3) calculation of document similarity using metrics such as Cosine, Euclidean and Jaccard and, 4) validation of the findings", "description": "Strategies and associated ML/NLP libraries that will be presented during the tutorial include:: \r\n\r\n1) Text/document pre-processing: \r\n    - Document pre-processing using NLTK library\r\n \r\n2) Feature extraction \u2013 word/sentence embedding: \r\n   - Term frequency \u2013 Inverse Document Frequency (TF-IDF) with the aid of the Scikit-Learn library \r\n   - Pre-trained GloVe embedding with the aid of FSE/Gensim library \r\n   - A pre-trained GloVe embedding re-trained with Smooth Inverse Frequency (SIF) from scratch aid of the FSE library \r\n   - Sentence embedding using Google\u2019s pre-trained Universal Sentence Encoder (USE) \r\n   - Sentence embedding using BERT via sentence-transformers library\r\n\r\n3) Similarity computations will be done using Scikit-Learn pairwise library module:  \r\n   - https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics.pairwise \r\n\r\n4) Visualization/Validation of findings: \r\n   - Dimensionality reduction using techniques such: PCA, TSNE, MDS and UMAP with the aid of Scikit-Learn library \r\n   - Visualization via scatter plot and heatmap with the aid of Matplotlib and Seaborn libraries \r\n   - Validation/comparision of the findings \r\n\r\n5) Datasets used include: \r\n   - A simple dataset of book titles sourced from: https://raw.githubusercontent.com/noahjett/Movie-Goodreads-Analysis/master/books.csv \r\n   - The classic 20 News Group data sourced from Scikit-Learn dataset module: https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html  \r\n   - STS benchmark dataset located here:  http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz further details on this benchmark can be found here: https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark", "recording_license": "", "do_not_record": false, "persons": [{"id": 13, "code": "JRLWFD", "public_name": "Ade Idowu", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}]}}, {"index": 2, "date": "2022-06-18", "day_start": "2022-06-18T04:00:00+01:00", "day_end": "2022-06-19T03:59:00+01:00", "rooms": {"Tower Suite 1": [{"id": 197, "guid": "10f8c574-19b9-5685-88e3-e473bb0e7897", "logo": "", "date": "2022-06-18T09:15:00+01:00", "start": "09:15", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-197-possible-futures-for-jupyter", "url": "https://london2022.pydata.org/cfp/talk/GLHHG8/", "title": "Possible Futures for Jupyter", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Jupyter has changed the way we think about interactive computing, scientific communication, and science education as it has been adopted globally, both in academia and industry.", "description": "In this talk, we present a bold vision for future applications and developments in the Jupyter ecosystem, some of which are just around the corner, while others are still mere possibilities, but have the potential for significant impact, for an even greater number of people.", "recording_license": "", "do_not_record": false, "persons": [{"id": 118, "code": "7EGUYV", "public_name": "Sylvain Corlay", "biography": "Sylvain Corlay is the founder and CEO of QuantStack. He holds a PhD in applied mathematics from University Paris VI.\r\n\r\nAs an open-source developer, Sylvain Corlay is active in the Jupyter ecosystem. He is the co-creator of the Voil\u00e0 dashboarding system and the Xeus C++ implementation of the Jupyter kernel protocol, and he maintains several other projects of the Jupyter stack. He is also a core contributor to conda-forge, and a several other scientific computing open-source projects, such as bqplot, xtensor, and ipyleaflet.\r\n\r\nBeyond QuantStack, Sylvain does a lot of volunteer work for the community, as a member of the board of directors of NumFOCUS, the vice chair of JupyterCon. He also co-organizes the PyData Paris Meetup.\r\n\r\nSylvain founded QuantStack in September 2016. Prior to founding QuantStack, he was a Quant Researcher at Bloomberg and an Adjunct Faculty member at the Courant Institute and Columbia University.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 158, "guid": "2867d599-b0e4-5ca6-8a21-e082424d8fb5", "logo": "", "date": "2022-06-18T10:15:00+01:00", "start": "10:15", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-158-a-bayesian-approach-for-measuring-song-novelty", "url": "https://london2022.pydata.org/cfp/talk/TPVUSG/", "title": "A Bayesian approach for measuring song novelty", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "This talk presents a Bayesian framework to cope with two challenges related to the measurement of song novelty (i.e., the innovativeness of a song\u2019s acoustic properties). First, analysts interested in measuring song novelty have to compare and contrast the acoustic attributes of a focal song against a meaningful set of reference \u2018songs\u2019. However, it is difficult to form an appropriate reference set of songs when markets comprise hundreds of 'fuzzy' music styles. Second, analysts have to understand how the individual acoustic attributes contribute to a song\u2019s \u2018overall\u2019 novelty. In the first part of the talk, I illustrate how Bayesian stats help analysts cope with these challenges. In the second part, I show the application of a Bayesian framework for song novelty measurement using Python and acoustic attributes from Spotify. Finally, I support the validity of my Bayesian framework with the results of a large-scale experiment conducted on Prolific.", "description": "1) Scope and relevance: appreciating the novelty of a song is key to selecting and marketing a piece of music \u2014 however, measuring novelty requires analysts to deal with longstanding issues. In this talk, I present an original Bayesian framework for measuring song novelty, and I show its merits relative to the extant measurement approaches based on dyadic (song-song) similarity of acoustic attributes; 2) Target audience: music market actors, music analytics, and new product development people; 3) The takeaway for the audience: familiarizing with a new approach for measuring song novelty; 4) Background knowledge: basic knowledge of statistics, NumPy, SciPy, Matplotlib; 4) Time breakdown: minutes 0 - 5: introduction to the problem of novelty measurement in heterogenous markets, such as the music market; minutes 5 - 15: illustration of the logic behind a Bayesian framework for measuring song novelty; minutes 15 - 30: Python implementation of the Bayesian framework and application to Spotify acoustic attribute data.", "recording_license": "", "do_not_record": false, "persons": [{"id": 92, "code": "9QDHTX", "public_name": "Simone Santoni", "biography": "I'm a senior lecturer at the Bayes Business School. My research, teaching, and industry experience concentrate on the areas of causal inference, network analysis, and NLP.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 32, "guid": "516af7b8-5fad-5baa-8c7b-5c790f256f70", "logo": "", "date": "2022-06-18T11:00:00+01:00", "start": "11:00", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-32-running-the-first-automatic-speech-recognition-asr-model-with-huggingface", "url": "https://london2022.pydata.org/cfp/talk/9MWNKW/", "title": "Running the first automatic speech recognition (ASR) model with HuggingFace", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Come and learn your first audio machine learning model with Automatic speech recognition (ASR) use case! ASR has been a popular application like voice-controlled assistants and voice-to-text/speech-to-text applications. These applications take audio clips as input and convert speech signals to text.", "description": "This talk is aiming for Python developers or ML practitioners who are knowing Python, and interested in working with audio machine learning use case. I will cover minimum slides about ML algorithm in this talk. Instead, I will walk through types of ASR applications, like a, b, and c. So you will know what are the occasions to work with ASR models. And talk about data processing of audio data, how to do feature extraction, and Fine-tune Wav2Vec2 using HuggingFace. The notebook that presented in the talk is running on Amazon SageMaker, the concept for this talk is cloud agnostic and applies to local computer(on premises) as well.", "recording_license": "", "do_not_record": false, "persons": [{"id": 105, "code": "E3PSMN", "public_name": "Mia Chang", "biography": "As a ML Specialist Solutions Architect, based in Berlin, Germany, Mia shares best practices around running AI/ML workload on AWS cloud with customers. Before she became the SA role, she has backend engineer and data scientist experience, solving machine problems end-to-end, from model training to model deployment. She enjoys working in tech industry due to the positive impact that technology brings to people's daily life. Talk with her: AI/ML on AWS; any suggestion for summer vacation plan :) Reach out her via: https://www.linkedin.com/in/mia-chang/", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 166, "guid": "37ae44bb-45a6-52d2-b596-7a3a4afbfc7a", "logo": "", "date": "2022-06-18T11:45:00+01:00", "start": "11:45", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-166-audio-neural-networks-without-ground-truth-how-to-avoid-humans-in-the-loop-at-all-costs", "url": "https://london2022.pydata.org/cfp/talk/VAEDUB/", "title": "Audio Neural Networks without Ground Truth: How to avoid humans in the loop at all costs", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Training audio neural networks requires creating or using pre-existing manually tagged data. In this talk we will review the state of the art algorithms that automate this process and show how they can help in real-world use-cases.", "description": "Manual listening tests are great but they\u2019re time consuming, mission specific and expensive. We all want good quality automated testing measurements to better our algorithms but can we truly get there?\r\n\r\nAdvanced techniques such as Visqol (Google ,2020) and NORESQA (Facebook 2021) are recent open source tools used to achieve automated model testing. They all aim to close the gap between our audio perception and the raw signal. Using them can help find the right path towards improvement, and have more confidence in our models.\r\n\r\nThis talk will point you in the right direction to start using automated audio tests in your work. We will explore the field through Python\u2019s Librosa library and go over the fundamental concepts and basic usage.\r\n\r\nWe\u2019ll also get a feeling for the power and variety of real-world use cases, by creating a test that explores a real-world example finding bugs in edge cases we didn\u2019t know. We\u2019ll finish with pointers and resources to help you get started.", "recording_license": "", "do_not_record": false, "persons": [{"id": 95, "code": "SWMLZE", "public_name": "Orian Sharoni", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 184, "guid": "ac8b8d25-1988-5c9d-80c0-5032ffa96742", "logo": "", "date": "2022-06-18T13:30:00+01:00", "start": "13:30", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-184-measurement-and-fairness-questions-and-practices-to-make-algorithmic-decision-making-more-fair", "url": "https://london2022.pydata.org/cfp/talk/ZEGBHJ/", "title": "Measurement and Fairness: Questions and Practices to Make Algorithmic Decision Making more Fair", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Machine learning is almost always used in systems which automate or semi-automate decision making processes. These decisions are used in recommender systems, fraud detection, healthcare recommendation systems, etc. Many systems, if not most, can induce harm by giving a less desirable outcome for cases where they should in fact give a more desired outcome, e.g. reporting an insurance claim to be fraud when indeed it is not.\r\n\r\nIn this talk we first go through different sources of harm which can creep into a system based on machine learning [1], and the types of harm an ML based system  can induce [2].\r\n\r\nTaking lessons from social sciences, one can see input and output values of automated systems as measurements of constructs or a proxy measurement of those constructs. In this talk we go through a set of questions one should ask before and while working on such systems. Some of these questions can be answered quantitatively, and others qualitatively [3].\r\n\r\n[1] Suresh, H., Guttag, J., Kaiser, D., & Shah, J. (2021). Understanding Potential Sources of Harm throughout the Machine Learning Life Cycle. MIT Case Studies in Social and Ethical Responsibilities of Computing, (Summer 2021). https://doi.org/10.21428/2c646de5.c16a07bb\r\n[2] The Trouble with Bias - NeurIPS 2017 Keynote - Kate Crawford, https://www.youtube.com/watch?v=fMym_BKWQzk\r\n[3] Jacobs, Abigail Z., and Hanna Wallach. \"Measurement and fairness.\" Proceedings of the 2021 ACM conference on fairness, accountability, and transparency. 2021.", "description": "In this talk we first go through different sources of harm that creep into a data based system, such as historical harm, representation bias, measurement bias, aggregation bias, learning bias, evaluation bias, and deployment bias. We then cover different types of harm that such a system can induce, two examples of which being allocation harm and quality of service harm.\r\n\r\nThen we move to measurement and fairness. Academics in social sciences use a different jargon than data scientists and computer scientists implementing automated systems. To bridge the gap, in this talk we explore concepts such as measurement, construct, construct validity, and construct reliability. We then go through concepts such as face validity, content validity, convergent validity, discriminant validity, predictive validity, hypothesis validity, and computational validity. By the end of this talk, you would be able to apply these lessons from social sciences in your daily data science projects to see if you should intervene at any stage of your product\u201a\u00c4\u00f4s life cycle to make it more fair.", "recording_license": "", "do_not_record": false, "persons": [{"id": 14, "code": "PJZEHU", "public_name": "Adrin Jalali", "biography": "I'm a computer scientist / bioinformatician who has turned to be a core developer of `scikit-learn` and `fairlearn`, and work as a Machine Learning Engineer at Hugging Face. I'm also an organizer of PyData Berlin.\r\n\r\nThese days I mostly focus on aspects of machine learning and tools which help with creating more ethical and fair decision making systems. This trend has influenced me to work on `fairlearn`, and to work on aspects of `scikit-learn` which would help tools such as `fairlearn` to work more fluently with the package; and at Hugging Face, my focus is to enable the community of these libraries to be able to share their models more easily and be more open about their work.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 147, "guid": "397f8326-decf-553a-9956-accf9ec5cc67", "logo": "", "date": "2022-06-18T14:15:00+01:00", "start": "14:15", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-147-can-you-read-this-or-how-i-improved-text-readability-on-the-web-for-the-visually-impaired-", "url": "https://london2022.pydata.org/cfp/talk/RLBA3K/", "title": "Can you Read This? (Or: how I Improved Text Readability on the Web for the Visually Impaired)", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "This talk will describe how I used deep learning to identify texts on a background image that are illegible for people with vision impairments. I will explain the challenges I encountered when using different OCR architectures for this task and talk about the original solution I came up with.", "description": "The web is a visual amusement park, full of colorful images, playful gifs, and funny videos. But when that visual richness is combined with text, people with low vision or color blindness increasingly struggle with the basic function of reading and thus can\u2019t fully enjoy what the web has to offer. In this talk, we will dive into the science of colors and how different people perceive them. We will discuss how color contrast affects text readability, and explain the challenge of estimating color contrast for text on image. We will also explore how modern deep learning tools such as OCR and text detection can be used for text classification based on readability. In addition, I will share my personal experience of working with visual data while having a visual impairment.", "recording_license": "", "do_not_record": false, "persons": [{"id": 19, "code": "UJ9KX7", "public_name": "Asya Frumkin", "biography": "Asya Frumkin is an algorithm developer and team lead, specializing in computer vision. She is also a proud Albino and visually impaired from birth. However, her disability never stopped her and gave her the irresistible drive to make a real impact. After building models in the automotive and medical imaging industries, it was fairly natural for her to join Evinced, a startup focused on improving digital accessibility. At Evinced she is responsible for end-to-end data solutions that help people like her take an equal part in the online world.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 195, "guid": "4ad4589c-67a2-5971-9f58-09808833708e", "logo": "", "date": "2022-06-18T15:00:00+01:00", "start": "15:00", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-195-data-pipelining-for-real-time-ml-models", "url": "https://london2022.pydata.org/cfp/talk/DUVNYJ/", "title": "Data Pipelining for Real-time ML Models", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Reinventing the wheel is usually not something we should be striving for, so why did we build our data pipeline from scratch? There are numerous design choices people make and they can highly affect the potential use cases. When making a custom pipeline you can make your own trade-offs between speed, throughput, simplicity and consistency of code/logic/data.\r\n\r\nMarket makers like Optiver are usually associated with ultra-low latency infrastructure, however there are plenty of use cases where human latency (seconds) is acceptable. Computing derived metrics, training models and making predictions as new data arrives are just a few such applications and what we will focus on in this presentation.\r\n\r\nWe will tackle some of the questions we asked ourselves on the design choices for our data pipeline. \r\n * Should you write code that is used by both live and historical pipeline?  \r\n * How to improve research to production cycle? \r\n * How do we ensure that real-time and backtest results match? \r\n * How to improve development speed? \r\n * What trade-offs to make if inputs/data arrive asynchronously? \r\n * How to improve performance and reduce resource usage? \r\n * How can we speed up day-to-day research? \r\n * What to do with stateful nodes? \r\n\r\nBasic knowledge of finance and data pipelining might be beneficial, but no specific knowledge is required to follow the presentation.", "description": "Predicting financial time-series is a challenge in itself, and doing it in real-time further increases the complexity. Ensuring that that the data matches between live (real-time) and historical (backtesting) applications is key for us. If they were to mismatch, the model would be less reliable for making trading decisions and could potentially lead to some terrible consequences. We will describe the trade-offs we made while designing our data pipeline through an example of an ML model.", "recording_license": "", "do_not_record": true, "persons": [{"id": 116, "code": "CNHQXL", "public_name": "Gabor Bakos", "biography": "Gabor works in the Statistical Arbitrage team at Optiver. He is responsible for building systematic trading strategies and designing the data pipelines. Prior to joining the team, he worked at a systematic hedge fund for 3.5 years. He holds an MSc degree in Mathematical and Computational Finance from the University of Oxford.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 203, "guid": "c51d261e-94c9-5396-9821-a9fe17f6f7e8", "logo": "", "date": "2022-06-18T16:00:00+01:00", "start": "16:00", "duration": "01:00", "room": "Tower Suite 1", "slug": "cfp-203-lightning-talks", "url": "https://london2022.pydata.org/cfp/talk/ECSWZG/", "title": "Lightning Talks", "subtitle": "", "track": null, "type": "Community Event", "language": "en", "abstract": "Lightning talks will take place at the end of the day on Saturday and Sunday in the plenary room. They will be 5-minute talks on any topic of interest for the PyData community. Sign-ups will be at the registration table. If we get more sign-ups than allotted spots we will randomly select talks out of a hat. We encourage anyone interested to sign-up for a 5-minute slot.", "description": "", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}, {"id": 201, "guid": "8f2ee48a-b6ec-507f-a78d-e722b1674b53", "logo": "", "date": "2022-06-18T17:00:00+01:00", "start": "17:00", "duration": "01:00", "room": "Tower Suite 1", "slug": "cfp-201-social-event-hosted-by-hopsworks", "url": "https://london2022.pydata.org/cfp/talk/989HCF/", "title": "Social Event -  Hosted by Hopsworks", "subtitle": "", "track": null, "type": "Community Event", "language": "en", "abstract": "Join us following the closing notes and lightning talks for an evening social hosted by Hopworks. Canap\u00e9s and first rounds of drinks are sponsored by Hopsworks with a cash bar available thereafter. Make sure to also enjoy one of the Hopsworks beers available to you at the bar. The social will be in the foyer (expo space) at the conference venue.", "description": "", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}, {"id": 202, "guid": "84f7afe4-9a7d-5ee0-9e52-edd0e748c89c", "logo": "", "date": "2022-06-18T18:00:00+01:00", "start": "18:00", "duration": "01:00", "room": "Tower Suite 1", "slug": "cfp-202-pub-quiz-hosted-by-quizmaster-james-powell", "url": "https://london2022.pydata.org/cfp/talk/EBJSEK/", "title": "Pub Quiz - hosted by quizmaster James Powell", "subtitle": "", "track": null, "type": "Community Event", "language": "en", "abstract": "During the social event, we will host our traditional pub quiz, hosted by quiz master James Powell, back in the main talk room. Come ready to meet your fellow community members, show off your knowledge and hopefully learn something new!", "description": "", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}], "Tower Suite 2": [{"id": 61, "guid": "d8e5d618-141f-5f9c-a246-8507ea7ac0bd", "logo": "", "date": "2022-06-18T10:15:00+01:00", "start": "10:15", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-61-making-fake-data-generators-for-open-source-healthcare-data-science-projects", "url": "https://london2022.pydata.org/cfp/talk/DLFUUF/", "title": "Making fake data generators for open source healthcare data science projects", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "", "description": "", "recording_license": "", "do_not_record": false, "persons": [{"id": 60, "code": "3QDXMW", "public_name": "Matthew Cooper", "biography": "Matt is a senior data scientist in the NHS AI Lab Skunkworks Team. In his role, he aims to help organisations across the NHS to get AI-driven applications into their hands quickly, helping data science and machine learning to help them in ways that are tailored to their day-to-day. He has a background in financial regulation and consultancy, and studied Aerospace Engineering at university.", "answers": []}, {"id": 42, "code": "ZK7MQH", "public_name": "Jennifer Hall", "biography": "Jennifer is a senior data scientist in the NHS AI Lab Imaging Team in the NHS England Transformation Directorate, exploring practical, innovative and ethical applications of AI across the NHS. Prior to this she studied Astrophysics at university and has worked in innovation, analytics and data science teams in the finance and travel industries.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 105, "guid": "cd2b77d5-8b24-53ff-a71b-54ebbcfb91bd", "logo": "", "date": "2022-06-18T11:00:00+01:00", "start": "11:00", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-105-how-pyodide-and-a-new-opensource-community-are-improving-children-s-social-work-", "url": "https://london2022.pydata.org/cfp/talk/K8XZDR/", "title": "How Pyodide and a new opensource community are improving children\u2019s social work.", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Social care workers support the most disadvantaged children in the UK and we help improve the sector with Data and Digital. Due to the extremely sensitive nature of the data in this context and long bureaucratic processes, data tools could neither be created to function on the internet nor could be installed by the users. This is a talk about how we coached social care workers to build a data cleaning tool and how Pyodide enabled it to scale. This talk is for people intrigued by complex problems. No previous knowledge is required.", "description": "Three years ago, we set out to figure out how Children\u2019s social care could be improved and found out that although large amounts of detailed data was generated, it was typically untrustworthy. Logistic constraints meant that data could only be cleaned once a year and by that time the insight was no longer as valuable. \r\nThe first fifteen minutes of the talk sets the full context; 151 distinct local authorities having large amounts of data but little insight; what it takes to scale a tool within the government and why Python and Pyodide were the most appropriate choices.\r\nThe next ten minutes will quantify the impact the tool has had and the opensource community of domain experts that now exist as a result of building the tool together.\r\nFinally, we will share other examples of  similar niche Python tools in the social sector.", "recording_license": "", "do_not_record": false, "persons": [{"id": 111, "code": "PPGAYA", "public_name": "Tambe Tabitha Achere", "biography": "Tambe Tabitha Achere works as a Data Analyst at Social Finance UK, a not-for-profit organisation that partners with governments, service providers, the voluntary sector, and the financial to tackle and scale solutions to social problems. \r\n\r\nHer work in the Data + Digital Labs involves combining research and tech to reimagine public and social services for the 21st century. This involves partnering with people and communities in developing deep understanding of their most challenging problems. Then working together to design and build innovative human-centred services, that are safe and trusted, and empower people to live happy and healthy lives.\r\n\r\nHow my name is pronounced\r\nTambe \u2013 The \u201cbe\u201d is pronounced as \u201cbear\u201d without the r.\r\nTabitha \u2013 Ta-bee-tha\r\nAchere \u2013 Both \u201ce\u201ds are short sounds. \u201ce\u201d as in egg.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 183, "guid": "78021700-bb72-5745-a906-4806f00c1119", "logo": "", "date": "2022-06-18T11:45:00+01:00", "start": "11:45", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-183-beyond-pandas-the-great-python-dataframe-showdown", "url": "https://london2022.pydata.org/cfp/talk/Z3NXF9/", "title": "Beyond pandas: The great Python dataframe showdown", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "The pandas library is one of the key factors that enabled the growth of Python in the Data Science industry and continues to help data scientists thrive almost 15 years after its creation. Because of this success, nowadays there are several open-source projects that claim to improve pandas in various ways, either by bringing it to a distributed computing setting (Dask), accelerating its performance with minimal changes (Modin), or offering slightly different API that solves some of its shortcomings (Polars).\r\n\r\nIn this talk we will go over some of the most widely used dataframe Python libraries beyond pandas, clarify the relationship between them, compare them in terms of project scope and proximity to the original pandas API, and offer advice on when to use each of them.\r\n\r\nIf you are a seasoned pandas user willing to explore alternatives, or a beginner user wondering what is all the fuzz about these new dataframe libraries, this talk is for you!", "description": "The pandas library is one of the key factors that enabled the growth of Python in the Data Science industry and continues to help data scientists thrive almost 15 years after its creation. Because of this success, nowadays there are several open-source projects that claim to improve pandas in various ways, either by bringing it to a distributed computing setting (Dask), accelerating its performance with minimal changes (Modin), or offering slightly different API that solves some of its shortcomings (Polars).\r\n\r\nThe outline of the talk goes as follows:\r\n\r\n1. Short introduction to the importance of pandas, and brief recollection of its main pain points (5 minutes)\r\n2. Enumeration of some alternatives, description of our classification (pandas-like vs bespoke, single-node vs distributed) (5 minutes)\r\n3. Presentation of the libraries using brief code snippets, visualization of the dependency relationships between them (20 minutes)\r\n4. Recommendations and conclusions (5 minutes)\r\n\r\nAfter the talk, you will have more information on how some of the modern alternatives to pandas fit onto the ecosystem, understand which ones provide the easiest migration path for an existing codebase, and be more prepared to judge which one to use for your next project. Prior exposure to pandas will help make the most of the presentation.", "recording_license": "", "do_not_record": false, "persons": [{"id": 91, "code": "XWUXFE", "public_name": "Juan Luis Cano Rodr\u00edguez", "biography": "Juan Luis (he/him/\u00e9l) is an Aerospace Engineer with a passion for STEM, programming, outreach, and sustainability. He works as Data Scientist Advocate at Orchest, where he empowers data scientists by building an open-source, scalable, easy-to-use workflow orchestrator. He has worked as Developer Advocate at Read the Docs, previously as software engineer in the space, consulting, and banking industries, and as a Python trainer for several private and public entities.\r\n\r\nApart from being a long-time user and contributor to many projects in the scientific Python stack (NumPy, SciPy, Astropy) he has published several open-source packages, the most important one being poliastro, an open-source Python library for Orbital Mechanics used in academia and industry.\r\n\r\nFinally, Juan Luis is the founder and former chair of the Python Espa\u00f1a association, the point of contact for the Spanish Python community, former organizer of PyCon Spain, which attracted more than 800 attendees in its last in-person edition in 2019, and current organizer of the PyData Madrid monthly meetups.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 180, "guid": "c7798c06-72c0-5e68-b23e-9d2c20c668b4", "logo": "", "date": "2022-06-18T13:30:00+01:00", "start": "13:30", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-180-machine-learning-2-0-with-hugging-face", "url": "https://london2022.pydata.org/cfp/talk/YQCLCY/", "title": "Machine Learning 2.0 with Hugging Face", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "In this session, we\u2019ll introduce you to Transformer models and what business problems you can solve with them. Then, we\u2019ll show you how you can simplify and accelerate your machine learning projects end-to-end: experimenting, training, optimizing, and deploying. Along the way, we\u2019ll run some demos to keep things concrete and exciting!", "description": "As amazing as state-of-the-art machine learning models are, training, optimizing, and deploying them remains a challenging endeavor that requires a significant amount of time, resources, and skills, all the more when different languages are involved. Unfortunately, this complexity prevents most organizations from using these models effectively, if at all. Instead, wouldn\u2019t it be great if we could just start from pre-trained versions and put them to work immediately?\r\n\r\nThis is the exact challenge that Hugging Face is tackling. Our tools make it easy to add state-of-the-art Transformer models to your applications. Thanks to popular open-source libraries (transformers, tokenizers, and datasets libraries, developers can easily work with over 4,000 datasets and over 38,000 pre-trained models in 160+ languages. In fact, with over 60,000 stars on GitHub, the transformers library has become the de-facto tool for developers and data scientists who need state-of-the-art models for natural language processing, computer vision, and speech.", "recording_license": "", "do_not_record": false, "persons": [{"id": 46, "code": "9UBJFZ", "public_name": "Julien Simon", "biography": "Julien is currently Chief Evangelist at Hugging Face. He's recently spent 6 years at Amazon Web Services where he was the Global Technical Evangelist for AI & Machine Learning. Prior to joining AWS, Julien served for 10 years as CTO/VP Engineering in large-scale startups.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 193, "guid": "31b9ddc3-c307-5959-a6d2-c92ba46e3f27", "logo": "", "date": "2022-06-18T14:15:00+01:00", "start": "14:15", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-193-understanding-your-bank-statement-in-100ms", "url": "https://london2022.pydata.org/cfp/talk/JFTB3G/", "title": "Understanding your bank statement in 100ms", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "In the last year, the global number of fintech companies has nearly **doubled**. Yet, despite the rapid growth, there is one area of banking that has been notoriously difficult to modernize: financial transactions. More than 1 **billion** transactions occur every day around the world. Transactions are different in every country and language, require knowledge of every merchant and location, depend on the context of the surrounding parties involved and are specific for each use case. At Ntropy, we enable developers to parse financial transactions in under 100ms with super-human accuracy, unlocking the path to a new generation of autonomous finance, powering products and services that have never before been possible. We will for the first time discuss the key parts of our pipeline, made possible by the latest advancements in natural language understanding and unsupervised learning.", "description": "Every large tech company is becoming a fintech. From Amazon merchant loans, to Google wallet, Apple card and Facebook payments. 82% of people use digital wallets, 45% of all global transactions are digital. Transaction data has the potential to become the key piece of intelligence to power the products and services of the future, including automated lending, credit scoring, insurance, and financial management, but also healthcare, fitness, gaming and more.\r\n\r\nHowever, decades of decentralized finance around the world has turned transactions into a tangled web of cryptic messages. Each financial transaction is a datapoint consisting of multiple modalities, including unstructured descriptions, amounts, currencies, directions of money movement, dates, locations, merchant category codes, and more. Due to regional inconsistencies, lack of unified standards and **tens of thousands** of merchants opening and closing down each day and with more than **200 million** companies globally (far beyond what any model can remember), human common sense was essential to make sense of this data. Until now.\r\n\r\nWith recent breakthroughs in natural language processing, weak supervision and multi-task learning, algorithmic understanding of this data has finally become possible. We will here introduce how we do this at scale at Ntropy.\r\n\r\nThe Ntropy API converts raw transactions into human-readable data points that we call \u201cenriched\u201d transactions, by combining data from multiple sources, including natural language models, search engines, internal databases, external APIs, and existing transaction data from across our network. There are 3 key parts of the pipeline:\r\n\r\n1. Extract all named entities from transaction descriptions (dates, locations, service words, merchant originators, receiving entity, payment processors, etc.)\r\n2. Uniquely identify these entities using entity linkage and information extraction across search engines and databases.\r\n3. Use the extracted information in combination with all of the information describing the transaction to translate this into a human understandable label.\r\n\r\nWe cannot forget that transactions are real-time and any form of processing has to typically be kept to **200ms** or less! These components are held together by an optimized infrastructure that scales our models to minimize inference latency and resource usage, while caching any intermediaries and can operate in and adapt to noisy, out-of-distribution data.\r\n\r\nFinally, as the meaning of each transaction depends on the type of account holder, industry and use case, a general model will never be the optimal solution. The Ntropy API allows developers to train custom modes with their own data, on top of embeddings provided by our base model. Such fine-tuned models can be trained with as few as **150 labels**, which can all be done by a single person in a few hours.\r\n\r\nThis talk is geared at practitioners interested in knowing how bank transactions can be understood by a machine. Expert knowledge of machine learning is not required.", "recording_license": "", "do_not_record": false, "persons": [{"id": 112, "code": "NMTDXU", "public_name": "Chady Dimachkie", "biography": null, "answers": []}, {"id": 113, "code": "PAF9UJ", "public_name": "Robin Kahlow", "biography": null, "answers": []}, {"id": 114, "code": "WNC88K", "public_name": "Dr. Jonathan Kernes", "biography": null, "answers": []}, {"id": 127, "code": "AYEM8V", "public_name": "Dr. Ilia Zintchenko", "biography": "CTO at Ntropy", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 51, "guid": "4914449d-9372-589a-be5f-aaaac43e458b", "logo": "", "date": "2022-06-18T15:00:00+01:00", "start": "15:00", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-51-large-language-models-for-real-world-applications-a-gentle-intro", "url": "https://london2022.pydata.org/cfp/talk/BXXHJ7/", "title": "Large Language Models for Real-World Applications - A Gentle Intro", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Machine language understanding and generation has been undergoing rapid improvements due to recent breakthroughs in machine learning (e.g. large language models like GPT and BERT). And while big tech and NLP engineers were quick to capitalize on these models, the broader developer community lags in adopting these models and realizing their potential in their business domains.\r\n\r\nThis talk provides a gentle and highly visual overview of some of the main intuitions and real-world applications of large language models. It assumes no prior knowledge of language processing and aims to bring attendees up to date with the fundamental intuitions and applications of large language models.", "description": "It's only been a couple of years since humanity reached a language technology breakthrough: software that can write as well as humans do. Large language models (LLMs) like GPT and BERT have taken the machine learning world by storm propelling both the language processing (NLP) and computer vision domains rapidly forward and bringing about a series of surprising application (e.g. DeepMind Gopher, OpenAI GPT3 and Dall-E, Google Pathways Language Model). But while big tech invests heavily in including these models into their products, developers and smaller companies still lag in adopting these models and realizing their potential in their business domains.\r\n\r\nThis talk provides a gentle and highly visual overview of real-world applications of large language models. It introduces some of the main intuitions to help developers and data scientist who are new to the topic. These include: - how LLMs are trained, - prompt engineering, - embeddings - finetuning\r\n\r\nThe talk then proceeds to some advanced use cases and practical tips & tricks for use cases such as: - Building LLM-based text classifiers - Semantic search (going beyond keyword search to searching by meaning) - Document clustering - Generating training data with generative language models\r\n\r\nThis talk assumes no prior knowledge of language processing and aims to bring attendees up to date with the fundamental intuitions and applications of large language models.", "recording_license": "", "do_not_record": false, "persons": [{"id": 101, "code": "UAEP3V", "public_name": "Jay Alammar", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}], "Tower Suite 3": [{"id": 84, "guid": "b6475a45-46b5-5cfe-9d6b-38cace8eb3ff", "logo": "", "date": "2022-06-18T10:15:00+01:00", "start": "10:15", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-84-fuzzy-matching-at-scale", "url": "https://london2022.pydata.org/cfp/talk/GCJPN3/", "title": "Fuzzy Matching at Scale", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Fuzzy Matching is a useful tool that has been well discussed. However, these popular methods based on edit-distances like *Levenshtein* or *Jaro-Winkler* have failed to keep up with increasing data sizes. This talk will walk you through modern methods based on *character-based n-grams*, *vector space models*, and *approximate nearest neighbours* for Fuzzy Matching at Scale.", "description": "Have you ever used *fuzzywuzzy* and waited forever for your results? This talk will propose an alternate implementation of Fuzzy Matching based on the following methods:\r\n\r\n- *character-based n-grams* that breaks up a search term into tokens of length n\r\n- *vector space models* like TF-IDF, GloVe or *word embeddings* like BERT\r\n- *approximate nearest neighbours* to speed up nearest-neighbours search\r\n\r\nThis talk is designed for an audience with intermediate knowledge of string algorithms and concepts in NLP like word embeddings. If that sounds like you, and you are tired of waiting for *fuzzywuzzy*, this is the talk for you!", "recording_license": "", "do_not_record": false, "persons": [{"id": 119, "code": "FDMEQ8", "public_name": "Thusal", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 129, "guid": "b7d07aa3-494a-56cc-aa7c-ea50004667ae", "logo": "", "date": "2022-06-18T11:00:00+01:00", "start": "11:00", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-129--off-with-their-i-os-or-how-to-contain-madness-by-isolating-your-code", "url": "https://london2022.pydata.org/cfp/talk/MTRBW7/", "title": "\u201cOff with their I/Os!\u201d - or how to contain madness by isolating your code", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Engulfed in a tedious refactoring of your code, you\u2019re adding the 7th layer of mocks to a test when you realise something must have gone wrong somewhere, but what ? You\u2019ve written readable code, split into functions and classes to avoid long chunks of code, and yet, every time, you end up with hardly testable code, a test suite that runs for hours, functions with seventeen arguments, and you wonder if it\u2019s you mocking the code or the code mocking you.\r\n\r\nFollow the white rabbit with me to learn about usual problems of code organization and I/O architecture, and some tricks on how to handle I/Os and dependencies isolation. We might encounter a bit of SOLID advice, and maybe even a nice hat!", "description": "The intended audience is intermediate to senior data scientists, who have already, or will soon encounter problems with testing, maintaining or expanding a growing codebase.\r\n\r\nThis talk will help you understand the benefits of good architecture, with a focus on isolating your I/O (inputs/ outputs) and other third-party dependencies, and guide through how to achieve it in practice, from simpler to more complex cases. I will present good practices coming from software engineering, with a focus on applying them to a data science context.\r\n\r\n*Outline*: - (2 min) Intro - (4 min) Functional programming ideas - (6 min) Isolating I/O with a clean architecture (\u201conion\u201d architecture) - (5 min) Benefits in terms of testing and maintainability - (8 min) How to isolate third-party dependencies using dependency injection and abstraction layers - (5 min) QA\r\n\r\nI cannot promise that the Liskov substitution principle won\u2019t be mentioned, but I will do my best to make it clear and understandable.", "recording_license": "", "do_not_record": false, "persons": [{"id": 93, "code": "A7AWK7", "public_name": "Sarah Diot-Girard", "biography": "Sarah Diot-Girard has been working with Machine Learning since 2012 and she enjoys using data science tools to find solutions to practical problems.  She is particularly interested in practical issues, both ethical and technical, coming from applying ML into real life.  She gave talks about data privacy and algorithmic fairness, and software engineering best practices applied to data science.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 156, "guid": "114b6ffc-4f82-57b3-b3db-005b7b1b82b8", "logo": "", "date": "2022-06-18T11:45:00+01:00", "start": "11:45", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-156-python-centric-feature-stores", "url": "https://london2022.pydata.org/cfp/talk/TLLRPC/", "title": "Python-centric Feature Stores", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Most enterprise data used by Data Scientists to train machine learning models is tabular data that comes from data warehouses and data lakes. Recent growth in the popularity of the modern data stack,  based on lakehouses like Snowflake, Delta Lake, Big Query, and Redshift, have led to growth in the use of SQL-centric tools for data engineers, such as DBT. However, Data Scientists' language of choice is Python. How do we square this circle?", "description": "In this talk, we investigate the role of the Feature Store for machine learning in enabling Python native access to enterprise data for both training and serving features to models. In particular, we will describe the problem of how to create point-in-time consistent training data from features spread over many tables using a SQL backend from Python. We will look at how some tools provide Python ORM-style support for generating SQL, while others make it easier for Data Scientists to embed SQL in their Python pipelines. We will then introduce a third way where we provide a domain-specific language in Python that transparently generates SQL that runs on backend platforms. We will work with a motivation example - the (important) problem with predicting the height of surf at a beach.", "recording_license": "", "do_not_record": false, "persons": [{"id": 104, "code": "NANXXE", "public_name": "Jim Dowling", "biography": "Jim is the Co-founder and CEO of Hopsworks", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 194, "guid": "3288f42e-a8aa-5c11-81c6-74ed80e9ee5b", "logo": "", "date": "2022-06-18T13:30:00+01:00", "start": "13:30", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-194-testing-testing-on-experimental-drift-and-data-driven-product-design", "url": "https://london2022.pydata.org/cfp/talk/YVFW7G/", "title": "Testing, testing: On experimental drift and data driven product design", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "A/B testing is (and should be) the gold standard for making data driven decisions. However, basing your decisions solely on tests can lead to very bad product decisions, primarily because of different types of hard-to-track changes to your environment (aka \"experimental drift\"). In this talk I will explain what experimental drift is and how it can affect your product design and A/B testing choices. I will also review a few strategies of handling drift as a data scientist working in a product team and show examples.", "description": "A/B testing is (and should be) the gold standard for making data driven decisions. However, basing your decisions solely on tests can lead to very bad product decisions, primarily because of different types of hard-to-track changes to your environment (aka \"experimental drift\"). In this talk I will explain what experimental drift is and how it can affect your product design and A/B testing choices. I will also review a few strategies of handling drift as a data scientist working in a product team and show examples.", "recording_license": "", "do_not_record": false, "persons": [{"id": 115, "code": "LQGGMY", "public_name": "Yizhar (Izzy) Toren", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 33, "guid": "4a61ff96-fd68-5778-932d-ced3eaf9d7d0", "logo": "", "date": "2022-06-18T14:15:00+01:00", "start": "14:15", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-33-models-schm-odels-why-you-should-care-about-data-centric-ai", "url": "https://london2022.pydata.org/cfp/talk/9PLJV7/", "title": "Models schm-odels: why you should care about Data-Centric AI", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Data Centric AI is the term coined by AI pioneer Andrew Ng for the movement that argues we shift our focus towards iterating on our data instead of models to improve machine learning predictions. But isn't this what we have always done? Why is this trend relevant now? Has something really changed, and if so, how does that change your work as a data scientist?\r\n\r\nThis talk will feature anecdotes and real-world examples of 'model-itis' that serve as an argument for data-centric AI, our lessons learned from winning the Data Centric AI competition, and practical tips on how you can integrate data-centric principles in your daily work.", "description": "Data Centric AI is the term coined by AI pioneer Andrew Ng for the movement that argues we shift our focus towards iterating on our data instead of models to improve machine learning predictions. But isn't this what we have always done? Why is this trend relevant now? Has something really changed, and if so, how does that change your work as a data scientist?\r\n\r\nThis talk will feature anecdotes and real-world examples of 'model-itis' that serve as an argument for data-centric AI, our lessons learned from winning the Data Centric AI competition, and practical tips on how you can integrate data-centric principles in your daily work.", "recording_license": "", "do_not_record": false, "persons": [{"id": 102, "code": "N8AN3F", "public_name": "Marysia Winkels", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 90, "guid": "5c6fe7ad-0249-502c-a654-8d0b8a7909b6", "logo": "", "date": "2022-06-18T15:00:00+01:00", "start": "15:00", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-90-unlocking-the-power-of-gradient-boosted-trees-using-lightgbm-", "url": "https://london2022.pydata.org/cfp/talk/HEC7QL/", "title": "Unlocking the power of gradient-boosted trees (using LightGBM)", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Gradient-boosted trees (XGBoost, LightGBM, Catboost) have become the staple of machine learning for tabular datasets. While most data scientists have made use of them at some point, many don\u2019t know the true power those Python libraries provide. I will take LightGBM as an example and show in practice how it handles missing value imputation and categorical encoding natively, the different loss functions it provides for different problems (including the creation of your own loss function!), and how to interpret the resulting models. My aim is to show how LightGBM is like a Swiss army knife for machine learning and why it is the most pragmatic choice for tabular problems.", "description": "This presentation is aimed at data science practitioners who deal with tabular (structured) datasets. Any company with a database will have a tabular dataset. Tabular problems include classification (e.g. predict fraud) and regression (e.g. predict revenue). Since the release of the XGBoost library, gradient-boosted trees (GBT) have dominated such problems in competitions like Kaggle when faced against any other machine learning model one-on-one. LightGBM is a newer and generally more efficient implementation of GBT algorithms.\r\n\r\nWhile most practitioners will have heard and perhaps used such GBT models, many don\u2019t know all the awesome features the modern libraries provide. This presentation aims to cover the most relevant features, explain them conceptually (e.g. how missing value imputation works behind the scene) and how to use them in practice (e.g. how to define your own custom loss function in Python). With this knowledge, you will be able to face any tabular dataset without having to resort to data cleaning tricks and deliver a performant model faster than any alternative (e.g. by using Scikit-learn, PyTorch or Tensorflow). \r\n\r\nHere are the topics to be covered:\r\n\r\n* Brief summary of the GBT algorithm: why is it better for tabular problems than linear or neural models?\r\n*  Missing value imputation: why not just use mean / median / mode  imputation?\r\n* Categorical encoding: why is it more convenient and performant than one-hot or label encoding?\r\n* The loss function menu: which objective should you use for which problem?\r\n* Custom loss functions: how to do it and why should you care?\r\n* Model interpretability: how to use SHAP and why it is better than the default method?\r\n* Pitfalls and takeaways: what can go wrong and what should you do next?\r\n* Q&A\r\n\r\nThe presentation will be accompanied by a notebook that will allow reproducibility and code sharing.", "recording_license": "", "do_not_record": false, "persons": [{"id": 84, "code": "JZCUAU", "public_name": "Pedro Tabacof", "biography": "Pedro Tabacof is based in Dublin and is currently a staff data scientist at Wildlife Studios (a mobile gaming company). Previously, he has worked at Nubank (fintech) and iFood (food delivery app). He has used and deployed machine learning models for anti-fraud, credit risk, lifetime value and marketing attribution, using XGBoost or LightGBM in almost all cases. Academically, he has a master's degree in deep learning and 300+ citations.", "answers": []}], "links": [], "attachments": [], "answers": []}], "Beaufort": [{"id": 199, "guid": "2dd1fd16-0f6d-58fa-bf87-4378cf849a18", "logo": "", "date": "2022-06-18T11:45:00+01:00", "start": "11:45", "duration": "00:45", "room": "Beaufort", "slug": "cfp-199-executives-at-pydata", "url": "https://london2022.pydata.org/cfp/talk/ZWPHS9/", "title": "Executives at PyData", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Executives at PyData is a facilitated discussion session for executives and leaders to discuss challenges around designing and delivering successful data projects, organizational communication, product management and design, hiring, and team growth.\r\n\r\nWe'll announce the agenda at the start of the session, you can ask questions or raise issues to get feedback from other leaders in the room, NumFOCUS board members and Ian and James.\r\n\r\nOrganized by Ian Ozsvald (London) and James Powell (New York)", "description": "", "recording_license": "", "do_not_record": false, "persons": [{"id": 38, "code": "TQ7QZY", "public_name": "Ian Ozsvald", "biography": "Ian is a Chief Data Scientist and Coach, he's helped co-organise the annual PyDataLondon conference with 700+ attendees and the associated 11,000+ member monthly meetup. He runs the established Mor Consulting Data Science consultancy in London, gives conference talks internationally often as keynote speaker and is the author of the bestselling O'Reilly book High Performance Python (2nd edition). He has 19 years of experience as a senior data science leader, trainer and team coach. For fun he's walked by his high-energy Springer Spaniel, surfs the Cornish coast and drinks fine coffee. Past talks and articles can be found at: \r\n\r\n* https://ianozsvald.com/\r\n* https://github.com/ianozsvald/\r\n* https://twitter.com/ianozsvald\r\n* https://www.linkedin.com/in/ianozsvald/", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 192, "guid": "75a50dfa-5d64-5a7c-b66a-b7145f27d78d", "logo": "/media/cfp/submissions/UQ8GD9/663px-Jupyter_logo.svg_TnjifSK.png", "date": "2022-06-18T13:30:00+01:00", "start": "13:30", "duration": "02:00", "room": "Beaufort", "slug": "cfp-192-make-your-first-jupyter-open-source-contribution", "url": "https://london2022.pydata.org/cfp/talk/UQ8GD9/", "title": "Make your first Jupyter open-source contribution", "subtitle": "", "track": null, "type": "Sprint", "language": "en", "abstract": "In this sprint, we will guide you step-by-step to show you how to make an open-source contribution to JupyterLab and other parts of Project Jupyter. We will start with a short tutorial on how to use Git and GitHub, how to author a change to a project, and how to open a pull request. We will also provide a list of curated issues that are straightforward to resolve to offer a good place to start. Make your first (or nth) Jupyter open-source contribution by opening a pull request today.", "description": "", "recording_license": "", "do_not_record": false, "persons": [{"id": 110, "code": "ZAUVAJ", "public_name": "Afshin T. Darian", "biography": "A. T. Darian is a Distinguished Contributor for Project Jupyter, is a Steering Council member, and maintainer. He works on JupyterLab, the integrated data environment for Jupyter notebook and data science. Visit his Github profile for full details: https://github.com/afshin", "answers": []}], "links": [], "attachments": [], "answers": []}]}}, {"index": 3, "date": "2022-06-19", "day_start": "2022-06-19T04:00:00+01:00", "day_end": "2022-06-20T03:59:00+01:00", "rooms": {"Tower Suite 1": [{"id": 204, "guid": "750546d6-0fb5-5c92-8573-e1a103dbcd6c", "logo": "", "date": "2022-06-19T09:00:00+01:00", "start": "09:00", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-204-keynote-key-challenges-in-the-pydata-ecosystem-and-how-we-can-all-make-a-difference", "url": "https://london2022.pydata.org/cfp/talk/RBYNTK/", "title": "Keynote: Key Challenges in the PyData Ecosystem and How We Can All Make a Difference", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "The PyData - and more broadly the scientific computing - ecosystem has seen massive growth both in adoption and complexity over the last few years, maybe decades. As for many other open-source ecosystems, this growth has also opened the door to complex socio-technical challenges. Many of which can directly impact the long-term sustainability of the ecosystem and its community.\r\n\r\nThis talk will dive into some of these current challenges and opportunities for us, the users, contributors, maintainers, activists, sponsors, and *insert many other hats* to help overcome those hurdles. \r\n\r\nAll while being intentional about the core tenents of collaboration, transparency, and openness that fuel our ecosystem.", "description": "", "recording_license": "", "do_not_record": false, "persons": [{"id": 128, "code": "DCUXKC", "public_name": "Tania Allard", "biography": "Tania is the co-director at Quansight Labs and previous Sr. Developer Advocate at Microsoft. She has vast experience in academic research and industrial environments. Her main areas of expertise are within data-intensive applications, scientific computing, and machine learning. Tania has conducted extensive work on the improvement of processes, reproducibility and transparency in research, data science and artificial intelligence. She is passionate about mentoring, open source, and its community and is involved in a number of initiatives aimed to build more diverse and inclusive communities. She is also a contributor, maintainer, and developer of a number of open source projects and the Founder of Pyladies NorthWest.\r\n\r\nIn her free time she likes tinkering with electronics, nerding with mechanical keyboards, reading all the books and lifting heavy weights.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 22, "guid": "3595c217-fb75-5371-94df-afc48544bc17", "logo": "", "date": "2022-06-19T10:15:00+01:00", "start": "10:15", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-22-solving-real-world-business-problems-with-bayesian-modeling", "url": "https://london2022.pydata.org/cfp/talk/8WRNQH/", "title": "Solving Real-World Business Problems with Bayesian Modeling", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Among Bayesian early adopters, digital marketing is chief. While many industries are embracing Bayesian modeling as a tool to solve some of the most advanced data science problems, marketing is facing unique challenges for which this approach provides elegant solutions. Among these challenges are a decrease in quality data, driven by an increased demand for online privacy and the imminent \"death of the cookie\" which prohibits online tracking. In addition, as more companies are building internal data science teams, there is an increased demand for in-house solutions.", "description": "In this talk I will explain how Bayesian modeling addresses these issues by (i) incorporating expert knowledge of the structure as well as about plausible parameter rangers; (ii) connecting multiple different data sets to increase circumstantial evidence of latent user features; and (iii) principled quantification of uncertainty to increase robustness of model fits and interpretation of the results. Inspired by real-world problems we encountered at PyMC Labs, we will look at Media Mix Models for marketing attribution and Customer Lifetime Value models and various hybrids between them.", "recording_license": "", "do_not_record": false, "persons": [{"id": 108, "code": "JLQJZR", "public_name": "Thomas Wiecki", "biography": "Dr. Thomas Wiecki is an author of PyMC, the leading platform for statistical data science. To help businesses solve some of their trickiest data science problems, he assembled some of the best Bayesian modelers out there and founded PyMC Labs -- the Bayesian consultancy. He did his PhD at Brown University.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 11, "guid": "b09e6097-86e7-574f-903a-18d03fd7fb01", "logo": "", "date": "2022-06-19T11:00:00+01:00", "start": "11:00", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-11-beyond-medical-image-segmentation-the-road-towards-clinical-insights-", "url": "https://london2022.pydata.org/cfp/talk/7R9TEG/", "title": "Beyond medical image segmentation. The road towards clinical insights.", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Recent progress in deep learning for medical imaging has led to impressive results. Among them is a fully automatic human organ segmentation from Computed Tomography (CT) scans. Organ segmentation can be the end goal in itself, e.g. when it is directly viewed by clinical teams. It can also serve as an input to diagnostic aid tools. Moreover, specific knowledge can be extracted out of segmentations to build databases. These databases can then be used for reasoning about the anatomy or planning treatment.\r\n\r\nIn this talk, we will describe a multi-stage pipeline for processing CT scans for abdominal aortic aneurysm (AAA) treatment planning. We will share our experience in sub-organ multilabel segmentation. We will discuss the challenges with common loss functions, and with metrics not being well aligned with clinical significance. We will show how enhanced segmentation can be used to represent patient anatomy in an accessible way for end-users who plan treatment for new patients.", "description": "One of the most impactful applications we can build with deep learning (DL) are tools for medical imaging analysis.\r\n\r\nIn this talk, you will learn about a DL-based tool for aortic care. Automated aorta segmentation removes lots of manual effort but this is just the beginning of what we can achieve with such data. The end goal is to understand which treatment options are possible and most likely to help an incoming patient. To do so we need to extract structured knowledge from the patient\u2019s anatomy and the previous cases in our database. We will describe our clinical decision support system. It is a tool for creating a database of historical cases in a form that makes it easy to inform treatment decisions for new cases.\r\n\r\nThe vascular system is different from other areas of the human body. A lot of information is contained in the shape (morphology) of the blood vessels and not necessarily in the contents of the organ, which transmits blood. That\u2019s why a segmentation and specifically its shape is very important to analyse.\r\n\r\nFirst, we will cover the challenges in 3D medical image segmentation such as: - data preparation - solving technical challenges with large models operating on large 3D arrays of data - a conceptual mismatch between the perceived quality of a segmentation model and commonly used volume-based metrics like the Dice coefficient\r\n\r\nWe will then discuss: - techniques which incorporate shape prior constraints to the learning algorithm - using domain knowledge to drive data representation\r\n\r\nWe will wrap up with an example of a multi-stage pipeline that incorporates semantic segmentation of CT scans, intensity-based measures, geometric features, and domain knowledge. The pipeline aims to guide clinical planning by finding similar patients in our database.", "recording_license": "", "do_not_record": false, "persons": [{"id": 7, "code": "HYQJTZ", "public_name": "Tomasz Bartczak", "biography": "I am a Machine Learning Engineer, motivated by applying state-of-the-art machine learning for a meaningful product.", "answers": []}, {"id": 96, "code": "7RHTAF", "public_name": "Adam Klimont", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 73, "guid": "5da0784d-1e8b-57e2-beb0-8b3ee29f233f", "logo": "", "date": "2022-06-19T11:45:00+01:00", "start": "11:45", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-73-extreme-multilabel-classification-in-the-biomedical-nlp-domain", "url": "https://london2022.pydata.org/cfp/talk/ETWLVJ/", "title": "Extreme Multilabel Classification in the Biomedical NLP domain", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Extreme multilabel classification refers to cases where the prediction space of a multilabel classifier is in the thousands of millions of labels which is an order of magnitude more than typical problems. The scale of such problems brings some unique challenges that one has to work around with such as memory, model size, train and inference time. This talk will discuss 1) how you can overcome those challenges, 2) relevant state of the art architectures for this problem 3) learning from the development of an transformers based nlp model to tag biomedical grants with 29K MeSH tags", "description": "Extreme multilabel classification refers to cases where the prediction space of a multilabel classifier is in the thousands of millions of labels which is an order of magnitude more than typical problems. For example, each Wikipedia article is tagged with more than one label, hence the name multilabel and extreme because there are millions of potential possibilities. Another notable example would be Amazon products. In our case, we were developing a classification scheme for biomedical grants for a large biomedical funder, based on the Medical Subject Headings (MeSH) which consist of around 29K tags.\r\n\r\nThe scale of such problems brings some unique challenges that one has to work around with. The first challenge is memory, since the size needed to represent the data often surpasses even large instances in the cloud. Then comes the model size which tends to be quite large, mainly due to the large vocabulary sizes but also the capacity needed to perform in such large output spaces. Lastly, training and inference times tend to require multi cpu or gpu instances depending on the model. In particular, inference time might be difficult to reduce to near real time due to the large number of labels the models need to consider.\r\n\r\nOver the course of two years, we experimented with a number of different approaches to the problem. We developed a custom neural network architecture inspired from Bert, Spacy and prior work which performed really well for a subset of the MeSH hierarchy. We also scaled to all 29K tags using both an extremely fast linear model from Amazon called XLinear and a transformer based architecture inspired from research called BertMesh (paper) which has close to state of the art performance. The linear model is currently in production tagging grants while the latter is uploaded in the HuggingFace hub and is free for everyone to use.\r\n\r\nIn this talk you will learn:\r\n\r\n- Ways to work with larger than memory data with certain characteristics,\r\n- An easy approach to reduce model size without hurting performance,\r\n- Some techniques to speed up training and inference time,\r\n- State of the art architectures in the area of extreme multilabel classification,\r\n- The learnings from working on this problem for the last two years", "recording_license": "", "do_not_record": false, "persons": [{"id": 65, "code": "ULYDP7", "public_name": "Nick Sorros", "biography": "Nick has been working as a data scientist for the last 10 years. Prior to setting up MantisNLP, he was working for the Wellcome Trust, initially to set up and lead the data science team. Prior to that he worked for a couple of startups at different stages of maturity from few to dozens of employees in various sectors such as fintech and social networks. Before data science, Nick was studying and doing research at Imperial College.\r\n\r\nDuring these years in the industry Nick found himself working more and more in NLP problems from detecting the language of tweets and identifying which entrepreneur statements were factual to tagging grants with thousands of labels and finding references in policy documents. This led him to create MantisNLP, a data science consultancy focused on NLP with a remote first culture and client worldwide.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 76, "guid": "b44e18a5-36be-59f7-bf8d-dafb1c286348", "logo": "", "date": "2022-06-19T13:30:00+01:00", "start": "13:30", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-76-accelerating-high-performance-machine-learning-with-huggingface-optimum-seldon", "url": "https://london2022.pydata.org/cfp/talk/FFAJRB/", "title": "Accelerating High-Performance Machine Learning with HuggingFace, Optimum & Seldon", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Identifying the right tools for high performance production machine learning may be overwhelming as the ecosystem continues to grow at break-neck speed. In this session showcase how practitioners can productionise ML models in scalable ecosystems in an optimizable way without having to deal with the underlying infrastructure challenges. We will be taking a GPT-2 HuggingFace model, optimizing it with ONNX and deploying to MLServer at scale using Seldon.", "description": "Identifying the right tools for high performant production machine learning may be overwhelming as the ecosystem continues to grow at break-neck speed. In this session we aim to provide a hands-on guide on how practitioners can productionise optimized machine learning models in scalable ecosystems using production-ready open source tools & frameworks.\r\n\r\nWe will dive into a practical use-case, deploying the renowned GPT-2 NLP machine learning model using MLServer and Seldon Core, which allows data scientists to productionise ML models without having to deal with the complexity of the underlying infrastructure - abstracting the complexity of the underlying model servers and runtime (Docker and Kubernetes) environments & frameworks.\r\n\r\nWe will showcase the foundational concepts and best practices to consider when leveraging production machine learning inference at scale. We will present some of the key challenges currently being faced in the MLOps space, as well as how each of the tools in the stack interoperate throughout the production machine learning lifecycle. Namely, we will introduce the benefits that the ONNX Open Standard and Runtime brings, as well as how we are able to leverage the optimized triton server and the orchestration framework Seldon Core to achieve a robust production machine learning deployment that can scale to your growing team / organisational needs.\r\n\r\nBy the end of this talk, attendees will have a better understanding of how they will be able to leverage these tools for their own models, as well as for the broad range of pre-trained models available. We will also provide a broad range of links and resources that will allow attendees do dive deeper into detailed areas, such as observability, scalability, governance, etc.", "recording_license": "", "do_not_record": false, "persons": [{"id": 9, "code": "HQFSQD", "public_name": "Alejandro Saucedo", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 3, "guid": "74296d61-b1cc-57b0-89ce-a2a2a7963149", "logo": "", "date": "2022-06-19T14:15:00+01:00", "start": "14:15", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-3-what-is-x-up-to-ner-and-relationship-extraction-for-information-extraction", "url": "https://london2022.pydata.org/cfp/talk/7DUKR7/", "title": "What is X up to? - NER and Relationship Extraction for Information Extraction", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Dealing with unstructured text to obtain information is one of the biggest aims in the field of natural language processing. In this talk, we will be demoing a solution where we have unstructured text on a particular topic, and we apply named entity recognition, together with relationship extraction, to extract structured data. We will be introducing our data source, the models that we use, and will be inspecting the end results, viewing particular statistics, and hovering over a graph, extracted from the raw text.", "description": "Relationship extraction is an essential task within the field of NLP, when we want to obtain structured data from raw text, in relational format. When we are to extract an information graph from raw text alone, named entity recognition provides us with the nodes in the graph, while relationship extraction gives us the edges (relations) between the nodes. And yet, relationship extraction is not as widely presented and demonstrated as a task, within the broad NLP community. In this talk, we are aiming to demo a solution where we have a news-based data source, and we are trying to obtain information on a particular topic. We will be viewing the raw text, seeing exploratory data analysis results, and moving on to see NER / Relex predictions taken on the data. Finally, we will be inspecting a graph that is formed based on the NER / Relex predictions that we have.", "recording_license": "", "do_not_record": false, "persons": [{"id": 6, "code": "JENBTM", "public_name": "Ahmet Melek", "biography": ".", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 198, "guid": "dbec2ef8-a094-5864-98ce-986fe5b1a847", "logo": "", "date": "2022-06-19T15:00:00+01:00", "start": "15:00", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-198-rethinking-data-visualisation-with-pyscript", "url": "https://london2022.pydata.org/cfp/talk/EBUENA/", "title": "Rethinking Data Visualisation with PyScript", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "PyScript leverages on the web browser to act as a ubiquitous virtual machine to deliver unprecedented Data Science use cases. Data Visualisation is the first and perhaps the most straightforward context in which PyScript can have its say. In this talk, we will present how PyScript can change the way data visualisation apps can be designed and delivered for complex data science use cases.", "description": "PyScript has great potentials to changing the way in which Data Science can be delivered and democratised completely. By running Python directly in the browser, you can really get the experience of running Python anywhere, any time using the browser as a ubiquitous Virtual Machine. \r\n\u200b\r\nData Visualisation is the first and perhaps the most straightforward context in which PyScript can have its say. In fact, PyScript enables the creation of self-contained data viz apps, bringing the full Scipy/PyData stack directly integrated with _interactive_ data visualisation frameworks, e.g. `bokeh` or `panel`. There's more! PyScript also allows direct integration with Javascript, allowing the development of full-fledged data viz apps using well-known JS library like `Altair` or `D3.js`\r\n\u200b\r\nIn this talk, we're going to introduce PyScript and we will present how PyScript can change the way data visualisation can be designed and delivered for complex data science use cases.", "recording_license": "", "do_not_record": false, "persons": [{"id": 120, "code": "UF9DHV", "public_name": "Valerio Maggio", "biography": "Valerio Maggio is a Researcher, Data scientist, and SSI fellow currently holding an appointment of Senior Research Associate in the [Dynamic Genetics Lab](https://dynamicgenetics.org/) at the [MRC Integrative Epidemiology Unit](http://www.bristol.ac.uk/integrative-epidemiology/), University of Bristol. Valerio holds a Ph.D. in Computer Science from University of Naples \"Federico II\" with a thesis on Machine Learning for Software Maintainability. Valerio is well versed into open research software, and best software development practice. His research interests span a broad range of topics in data science, from data processing to reproducible analytics, specifically focused on addressing challenges in public health. Valerio is also an open-source contributor, and active member of the Python community, where over the years he has led the organisation of many international conferences like PyCon/PyData Italy, and EuroSciPy. In 2019 Valerio has been awarded the honorary position of Microsoft Azure Cloud Research Software Engineer due to its work for Scalable Machine Learning pipelines on Microsoft Azure.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 206, "guid": "da960077-4224-5f2c-b473-34f08d777af9", "logo": "", "date": "2022-06-19T16:00:00+01:00", "start": "16:00", "duration": "00:45", "room": "Tower Suite 1", "slug": "cfp-206-keynote-by-dr-susan-mulcahy", "url": "https://london2022.pydata.org/cfp/talk/CMUKD8/", "title": "Keynote by Dr. Susan Mulcahy", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Dr Susan Mulcahy is the Director of the Data Sparks Programme at the Imperial College London, the innovative student placement programme matching a real world industry project on data science with a team of our postgraduate students. This programme sits within Imperial Business Analytics, the research centre focused on bringing data science research closer to the world of business. Susan was previously the Senior Education Fellow of the Data Science Institute (DSI) at Imperial where she developed the educational offering of the DSI for internal students and external industry engagements. She is also a Lecturer in Data Analytics at Ada National College for Digital Skills.  Having also facilitated technical courses for corporate clients since 2013, Susan enjoys teaching/facilitating/presenting technical topics to a general audience.\r\n\r\nSusan received her data-driven PhD from Imperial\u2019s Bioengineering Department in 2016 where she researched indicators of traumatic brain injury using MATLAB on datasets collecting over 500 million data points per patient per day. In addition to this, she has an MBA from INSEAD in France and a BSc in Mechanical Engineering from Purdue University in the USA. Susan has been a Fellow of the Royal Geographical Society since 2002.\r\n\r\nFor outside interests, Susan seeks out adventure. In 1999, she spent three months riding her bicycle across the USA. These days, she can be found rowing weekly on the Thames (anything from singles to 8s, outside of lockdown), hiking up a rugged mountain in the Scottish Highlands, or sleeping in a tent in her back garden in London (which she did for 82 consecutive nights in lockdown v1.0 in search of a local adventure.)\r\n\r\n\u201cLife is either a daring adventure or nothing.\u201d \u2013 Helen Keller", "description": "", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}, {"id": 205, "guid": "01d43ad6-4ab5-5613-b80a-213c8a78d47d", "logo": "", "date": "2022-06-19T16:45:00+01:00", "start": "16:45", "duration": "01:00", "room": "Tower Suite 1", "slug": "cfp-205-lightning-talks", "url": "https://london2022.pydata.org/cfp/talk/RBNVXT/", "title": "Lightning Talks", "subtitle": "", "track": null, "type": "Community Event", "language": "en", "abstract": "Lightning talks will take place at the end of the day on Saturday and Sunday in the plenary room. They will be 5-minute talks on any topic of interest for the PyData community. Sign-ups will be at the registration table. If we get more sign-ups than allotted spots we will randomly select talks out of a hat. We encourage anyone interested to sign-up for a 5-minute slot.", "description": "", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}], "Tower Suite 2": [{"id": 1, "guid": "5640e5d0-9fa2-5553-9777-f60bef292362", "logo": "", "date": "2022-06-19T10:15:00+01:00", "start": "10:15", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-1-a-hitchhiker-s-guide-to-mlops", "url": "https://london2022.pydata.org/cfp/talk/3U3RJZ/", "title": "A Hitchhiker\u2019s Guide to MLOps", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Bringing Machine Learning (ML) applications to a live production phase comes with all the same challenges of traditional software development, and more. Examples are: large datasets, tracking data quality and models quality, experiments reproducibility, and monitoring a live application. This talk is a grounded introduction to monitoring the ML lifecycle with only open source software.", "description": "Bringing your Machine Learning (ML) project from your local Jupyter notebook is often not that obvious. The set of tasks needed for \"productionalizing\" an ML project are now called **MLOps**.\r\n\r\nAlthough MLOps shares similarities with traditional software development and IT operations (DevOps), it also introduces new challenges such as large datasets, ongoing experiments and the unpredictable behavior of live ML models. One of the most common pitfalls is releasing a ML application in the wild without monitoring it, only to find out it has gone out of control.\r\n\r\nBut **don't panic**! Following your ML application in its lifecycle is easier than what you think with Python and already available open source software.\r\n\r\nAs a part of this practical introduction **I will cover**:\r\n\r\n- Traditional ML development VS MLOps driven ML development (*3 mins*)\r\n- Key concepts and common pitfalls in MLops (*5 mins*)\r\n- MLFlow for data and model tracking in Python (*5 mins*)\r\n- MLFlow for experiment reproducibility (*5 mins*)\r\n- Grafana for human friendly monitoring of a live ML application (*5 mins*)\r\n- Conclusions and examples on how to contribute to these projects (*2 mins*)\r\n\r\n**Why should you attend this talk?**\r\n\r\nAnyone interested with developing ML applications in a production environment, such as ML Engineers, Data Scientists, or ML product owners. I specifically focus on tips and tricks that will help you getting started with monitoring ML applications.\r\n\r\n**Who can attend this talk?**\r\n\r\nTo maximize the value of this talk, it is recommended that you are familiar with the basics of machine learning and Python programming.", "recording_license": "", "do_not_record": false, "persons": [{"id": 4, "code": "AVTW9Y", "public_name": "Davide Frazzetto", "biography": "Heya!\r\n\r\nI am Davide, Machine Learning Operations Engineer at Massive Entertainment \u2013 A Ubisoft Studio, and Pythonista at heart.\r\n\r\nI have spent the past 7 years working with data science, both researching and developing machine learning applications and data platforms. My main interest is in bridging the gap between development and production in machine learning world.\r\nEventually I decided to go back to one of my original passions and landed in the videogames industry, excited to get for Avatar: Frontiers of Pandora and Star Wars released soon!\r\n \r\nWhen I am not making or playing videogames, I like to keep myself active biking, bouldering, practicing yoga, and finally learning how to swim.\r\nI am also an active community builder in and out IT, with a strong interest in local NGOs communities in my city, Copenhagen. It is not hard to find me around the city making food with my non-profit restaurant One Bowl.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 178, "guid": "73a3ddd8-f2e0-56c2-86bb-a07262901f4c", "logo": "", "date": "2022-06-19T11:00:00+01:00", "start": "11:00", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-178-notebooker-production-and-scheduling-for-your-jupyter-notebooks", "url": "https://london2022.pydata.org/cfp/talk/YB8NL8/", "title": "Notebooker: Production and Scheduling for your Jupyter Notebooks", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Notebooker is an open-source web-based mongo-backed application which can help you turn your Jupyter Notebooks into reports which can be parametrised, scheduled, and shared in a few clicks. In this talk, I introduce Notebooker, how it works, and how it can help you.", "description": "Production-ise and schedule your Jupyter Notebooks, just as interactively as you wrote them. Notebooker is a webapp which can execute, parametrise, and schedule Jupyter Notebooks as soon as they have been committed to git. The results are stored in MongoDB and searchable via the web interface, essentially turning your Jupyter Notebook into a production-style web-based report in a few clicks. In this talk I will introduce Notebooker, dive into some details as to how it works, and present some use-cases which have popped up over the years.", "recording_license": "", "do_not_record": false, "persons": [{"id": 103, "code": "XNLLDN", "public_name": "Jon Bannister", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 37, "guid": "3ed7f7fc-57d2-5ddb-ada7-96c7134280ee", "logo": "", "date": "2022-06-19T11:45:00+01:00", "start": "11:45", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-37-clean-architecture-how-to-structure-your-ml-projects-to-reduce-technical-debt", "url": "https://london2022.pydata.org/cfp/talk/9WM3AR/", "title": "Clean Architecture: How to structure your ML projects to reduce technical debt", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Software engineering principles are frequently mentioned as a solution to data science's productivity problem. Unfortunately, rarely in a comprehensive format to be actionable or adopted for data-intensive use.\r\n\r\nIn this talk, I will present a framework that enables practitioners to structure their projects and manage changes throughout the product lifecycle at low effort.\r\n\r\nAudience will also learn about a minimum set of programming concepts to make this a reality.\r\n\r\nThe key takeaway for any Data Scientist is that you don't need to be a master programmer to start taking care of your own codebase.", "description": "Donald Knuth said that the most important system design principle is \"Layers of Abstraction\". More often than not, Data Science solutions break this principle leading to technical debt and a reduced ability to react to changes.\r\n\r\nI will introduce the concept of Clean Architecture and the importance of decoupling in machine learning systems. We will look into how it resolves acute problems throughout the product lifecycle.\r\n\r\nI will also introduce a minimal set of techniques to enable a refactoring cycle to move their legacy projects into the framework:\r\n- Domain Data Model \r\n- Dependency Inversion \r\n- Adapter/Factory/Strategy design patterns\r\n\r\nI will discuss economic and psychological rationale across the talk to justify the steps from business perspectives.", "recording_license": "", "do_not_record": false, "persons": [{"id": 80, "code": "YHMEAB", "public_name": "Laszlo Sragner", "biography": "I run Hypergolic, a boutique consultancy in London specialising in Machine Learning Product Management.\r\n\r\nFormerly I was Head of Data Science at Arkera, a fintech startup in London, where I built market intelligence products with Natural Language Processing for Tier 1 investment banks and hedge funds.\r\n\r\nPrior to that, I worked in mobile gaming for King Digital (makers of Candy Crush), specialising in player behaviour and monetisation. \r\n\r\nI started my career as a quant researcher writing trading strategies at multiple investment managers.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 132, "guid": "ca6d2d2b-c8eb-5195-bdce-18e27d10739d", "logo": "", "date": "2022-06-19T14:15:00+01:00", "start": "14:15", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-132-feature-engineering-for-time-series-forecasting", "url": "https://london2022.pydata.org/cfp/talk/NKEZPP/", "title": "Feature engineering for time series forecasting", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "To use our favourite supervised learning models for time series forecasting we first have to convert time series data into a tabular dataset of features and a target variable. In this talk we\u2019ll discuss all the tips, tricks, and pitfalls in transforming time series data into tabular data for forecasting.", "description": "Forecasting is the process of making predictions about the future based on past data. In the most traditional scenario, we have a time series and want to predict its future values. There are some challenges in creating forecasting features:\r\n\r\n- we need to transform time series data into tabular data with a well-designed set of features and a target variable;\r\n- when creating forecasting features we need to be extra careful to avoid data leakage via look-ahead bias;\r\n- time series data, as expected, changes over time; we need to take this into account when building forecasting features;\r\n- predicting the target value at multiple timesteps in the future requires us to think carefully about how to extrapolate our features from the past into the future.\r\n\r\nWe can forecast future values of the time series using off-the-shelf regression models like linear regression, tree-based models, support vector machines, and more. However, these models require tabular data as input. For forecasting we don\u2019t start with a table of features and a target variable, but instead a set of time series, perhaps just one. We need to transform the time series into tabular data with a target variable and a set of features that can be used by supervised learning models. Therefore, the main challenge is about creating a well-designed target variable and specially designed features that allow us to predict the future value of a time series.\r\n\r\nCreating the target variable and features for time series forecasting comes with its own pitfalls. A major concern is a form of data leakage known as look-ahead bias. This is where you accidentally use information that is only known in the future, not at predict time, to make a prediction. This can give you the illusion that you have a great forecasting model, however, in practice it will not perform. It is very easy to introduce look-ahead bias during feature engineering and we show how you can avoid it.\r\n\r\nTime series data change over time, that is, future data may or may not have the same distribution and patterns that we have in past data, this is different from the assumptions made about traditional tabular data. This change in distribution and patterns over time is called non-stationarity. In time series data, the simple presence of trend and seasonality can cause non-stationarity. Creating features that capture this dynamic is thus a challenge in time series forecasting.\r\n\r\nWe very often want to forecast multiple timesteps into the future. There are multiple ways to do this, such as 1) recursively applying a model that is built to forecast one step ahead, and 2) building a model that directly forecasts the target at a later time period in the future. A challenge is that the feature engineering required for these two methods are different.\r\n\r\nHow can we create a set of features that allow us to predict future values of a time series based on its past values? And how can we add additional information to create a richer dataset for our forecasts? In this talk we will discuss all of these topics and more.", "recording_license": "", "do_not_record": false, "persons": [{"id": 100, "code": "MXMSQC", "public_name": "Kishan Manani", "biography": "Kishan is a machine learning and data science lead, course instructor, and open source software contributor. He contributes to well known Python packages including Statsmodels and Feature-engine.  He has 10+ years of experience in applying machine learning and statistics in finance, e-commerce, and healthcare research. He leads data science teams to deliver data and machine learning products end-to-end. \r\n\r\nKishan attained a PhD in Physics from Imperial College London in applied large scale time-series analysis and modelling of cardiac arrhythmias; during this time he taught and supervised undergraduates and master's students.\r\n\r\nTwitter: @KishManani\r\n\r\nLinkedin: In/kishanmanani\r\n\r\nMedium: medium.com/@kish.manani\r\n\r\nWebsite: https://www.courses.trainindata.com/p/feature-engineering-for-forecasting", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 122, "guid": "87fc574b-7153-51b6-816f-5635d3063429", "logo": "", "date": "2022-06-19T15:00:00+01:00", "start": "15:00", "duration": "00:45", "room": "Tower Suite 2", "slug": "cfp-122-signature-methods-for-time-series-data", "url": "https://london2022.pydata.org/cfp/talk/LUMVRL/", "title": "Signature methods for time series data", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Signatures are a mathematical tool that arise in the study of paths. Roughly speaking, they capture the fine structure of a path. It turns out that signatures are extremely useful for analysing time series data in a data science context. This is party because they can take irregularly sampled, highly oscillatory data and produce a single array of values of fixed size which can then be used as features in predictors etc. In this talk I will give a brief introduction to signatures and give a brief demonstration of how you can use them to analyse time series data. No mathematical background will be assumed.", "description": "Signatures arise from the study of rough paths originating with Terry Lyons and his numerous collaborators over the past 20 years. If we think of a path as a sequence of sampled values in n-dimensional space, then the (truncated) signature of this path over a particular interval in the parameter space is a free tensor (sum of \"square\" d-dimensional numpy arrays for values of d up to the truncation level flattened out into a 1-d array) that describes the oscillation of the path over this interval.\r\n\r\nSignatures have been used in a wide variety of contexts to generate features in machine learning, usually resulting in an improvement over other techniques. For example, signatures were used to great effect in analysing sepsis data and in handwriting recognition (on the MNIST dataset), and human action recognition.\r\n\r\nThere are several open source libraries for computing signatures in Python including esig, iisignature, and signatory. (The latter is based on PyTorch and is easily integrated into Torch deep learning models.)\r\n\r\nIn the first half of the talk I will give a very high level overview of what a signature is and how it is computed. In the second half of the talk I will demonstrate how to use signatures in a simple example.", "recording_license": "", "do_not_record": false, "persons": [{"id": 106, "code": "URUADE", "public_name": "Sam Morley", "biography": "I am a research software engineer working on the DataSig project. This project is all about bringing rough path theory and signature methods to data science applications. I maintain the Python package esig for computing signatures and the C++ library libalgebra that backs esig, along with various other similar libraries. Prior to this role I worked as a lecturer in mathematics, and I am the author of the book \"Applying Math with Python\".", "answers": []}], "links": [], "attachments": [], "answers": []}], "Tower Suite 3": [{"id": 15, "guid": "9ff13cc2-dcc9-5305-b36c-feccf4e3ade4", "logo": "", "date": "2022-06-19T10:15:00+01:00", "start": "10:15", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-15-using-graph-neural-networks-to-embrace-the-dependency-within-your-data", "url": "https://london2022.pydata.org/cfp/talk/7WJDJA/", "title": "Using graph neural networks to embrace the dependency within your data", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Many machine learning models we use today have the core assumption that our data needs to be tabular, but how often is this truly the case? What if our data points are not independent? By ignoring the potential interrelatedness of our data, do we lose meaningful information that our models cannot leverage? In this talk, we shall explore graph neural networks and highlight how they can solve interesting problems in a way that is intractable when limiting ourselves to using tabular data.\r\n\r\nWe will look at the limitations of common algorithms and highlight how some clever linear algebra enables us to incorporate more meaningful information into our models. Social network data is a popular example of where relationships are relevant but relationships exist in many types of data where it may not be so obvious. Whether it's e-commerce, logistics or molecular data, relationships within your data likely exist and making use of them can be incredibly powerful.\r\n\r\nThis talk will hopefully spark your curiosity and provide you with a way of looking at problems from a new angle. It is intended for anyone with an interest in machine learning and will only lightly touch on some technical details.", "description": "Representing data in a tabular way is almost second nature to us and we seldom think about the limitations this can cause. This talk aims to help attendees develop an intuition for how graph neural networks (GNNs) can potentially solve their problems more effectively by accounting for the relationships present in our data. With tools like Neo4j, Spark and PyTorch Geometric, implementing GNNs has never been easier.\r\n\r\nBelow is a rough outline of the schedule of the talk:\r\n\r\n0-5 minutes: - Introduction to talk - Limitations of methods that require tabular datasets - Examples of different problems and how data can be represented as a graph\r\n\r\n5-15 minutes: - Explain how we go from a graph of nodes/edges to a matrix representation - Theory of message passing and convolutions as a way to change the representation of a graph - Different types of problems we can solve: node prediction, link prediction, graph-level classification\r\n\r\n15-25 minutes: - Provide one detailed use-case (link prediction task) - List open-source frameworks that can help implement GNNs - If time permits, share personal experiences/challenges\r\n\r\n25-30 minutes: - Q&A", "recording_license": "", "do_not_record": false, "persons": [{"id": 86, "code": "9UR7T7", "public_name": "Usman Zafar", "biography": "Usman Zafar is a Machine Learning Engineer at GoDataDriven. He has worked for several years as a Data Scientist, eventually moving into a Machine Learning Engineering role where he could focus more on the implementation of machine learning models in a scalable way. More recently, he has been interested in graph neural networks from the mathematical and engineering perspective as well as their ability to solve interesting problems in a new way.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 43, "guid": "66cf483b-bd09-59cb-9b83-d5b6a9827518", "logo": "", "date": "2022-06-19T11:00:00+01:00", "start": "11:00", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-43-clusterf-ck-a-practical-guide-to-bayesian-hierarchical-modeling-in-pymc3", "url": "https://london2022.pydata.org/cfp/talk/AN9ESK/", "title": "Clusterf*ck: A practical guide to Bayesian hierarchical modeling in Pymc3", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "At Apollo Agriculture, a Kenya based agro-tech startup, one of the challenging problems we face is to predict yields of Kenyan maize farmers. Like almost all data-sets, this data-set has a hierarchical structure: farmers within the same region aren\u2019t independent. By ignoring this fact, a model could predict yields entirely from the region of the farmer, but fails to find any other meaningful insights, and we may not even realize. However, if we \u201covercorrected,\u201d treating each region as completely separate, each individual analysis could be underpowered. Enter the hero of our story: Bayesian hierarchical modeling. Using a practical example in Pymc3, we\u2019ll follow this hero as they identify and overcome clustered data-sets.", "description": "With the lack of practical guides to use Bayesian hierarchical modeling in Python, many data scientists have shied away from using it. Using Pymc3, this talk will step through the process of using BHM on a real world hierarchical data-set. This walkthrough is aimed at all (data) scientists and researchers wanting to learn 1) how to recognize hierarchy in their data, 2) whether it matters, and 3) how to address it.\r\n\r\nEvery data-set has some degree of hierarchical structure, meaning that there are clusters in the data-set that are not completely independent.\r\n\r\nAt Apollo Agriculture, a Kenya based agro-tech startup, one of the challenging problems we face is to predict yields of Kenyan maize farmers. The data we work with has a hierarchical structure: farmers within the same region aren\u2019t independent. We tried ignoring this hierarchical structure, and trained a (black box) machine learning model that predicted yields using all data (aka pooling). However, even when we excluded the region as a variable, the model made predictions based on variables that were a proxy of region, without us even knowing. The model did not learn any other meaningful relationships, because it spent all its power on detecting the hierarchy that we already knew.\r\n\r\nTo prevent this from happening, this talk will help you: \r\n* Recognize hierarchy in your data-set \r\n* Understand when this hierarchy might be important or worth addressing \r\n* Address hierarchy in your data in a way that helps you get the most out of it\r\n\r\nTo address hierarchy in our data, we are looking for a technique that enables us to use the whole dataset simultaneously to fit the model parameters that share information across datasets and therefore reduce the model uncertainty. To further increase our statistical power, we want to incorporate prior scientific information about model parameters. We found that Bayesian hierarchical modeling helps us do exactly that. The brilliance of this approach is that the model allows for learning the degree to which you should consider different clusters as separate versus pooled, and helps you extract maximum value out of the data.", "recording_license": "", "do_not_record": false, "persons": [{"id": 98, "code": "7CAYXN", "public_name": "Hanna van der Vlis", "biography": "Hanna is a creative and passionate data scientist with experience in energy, agriculture, and credit risk. She has 3+ years of experience in data science and machine learning, and proven skills in ML Ops. She is currently working to help Kenyan smallholder farmers run more profitable businesses at Apollo Agriculture.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 134, "guid": "8fbbbc22-cb68-5f0e-997a-88d21d7a9af5", "logo": "", "date": "2022-06-19T11:45:00+01:00", "start": "11:45", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-134-don-t-stop-til-you-get-enough-hypothesis-testing-stop-criterion-with-precision-is-the-goal-", "url": "https://london2022.pydata.org/cfp/talk/NN9VNJ/", "title": "Don't Stop 'til You Get Enough - Hypothesis Testing Stop Criterion with \u201cPrecision Is The Goal\u201d", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "In hypothesis testing the stopping criterion for data collection is a non-trivial question that puzzles many analysts. This is especially true with sequential testing where demands for quick results may lead to biassed ones. I show how the belief that Bayesian approaches magically resolve this issue is misleading and how to obtain reliable outcomes by focusing on sample precision as a goal.", "description": "Hypothesis testing may come off as a dark art. On the one hand, data collection is expensive. On the other, small data sets may not yield enough statistical significance to draw meaningful conclusions. Combining these constraints with stakeholder requirements for quick answers from data makes the task of choosing the sample size stopping criterion a challenging balancing act.\r\n\r\nThis is especially true if the data is collected in a sequential manner, where a person, or an algorithm,  needs to determine when to stop collecting data to satisfy the project requirements without introducing confirmation bias.\r\n\r\nThis talk is targeted to anyone involved in experimentation, technical or managerial, and is interested in improving how they plan an experiment budget and conduct post data collection interpretation. A basic understanding of statistics and hypothesis testing experience are nice-to-haves but not essential as I will outline the basics.\r\n\r\nIn this talk you will learn why even though Bayesian approaches are more reliable than Frequentist ones for small data sets they do not magically solve the problem of confirmation bias. This will be followed with an introduction to John Kruschke's **\u201cPrecision is the Goal\u201d** method, where by determining in advance the experiment expected precision level yields robust results.\r\n\r\nDemonstrating on a [pythonic demo calculator](https://share.streamlit.io/elzurdo/sample-calculator/main/apps/audit_calculator/audit_calculator.py) I conclude with a discussion of the importance of communication of the considerations with stakeholders for expectation management.", "recording_license": "", "do_not_record": false, "persons": [{"id": 50, "code": "88YQNY", "public_name": "Eyal Kazin \u05d0\u05d9\u05dc \u05e7\u05d0\u05d6\u05d9\u05df", "biography": "Ex-cosmologist turned data scientist with over 15 years experience in solving challenging problems. I am motivated by intellectual challenges, highly detail oriented and love visualising data results to communicate insights for better decisions within organisations.\r\n\r\nMy main drive as a data scientist is applying scientific approaches that result in practical and clear solutions. To accomplish these, I use whatever works, be it statistical/causal inference, machine/deep learning or optimisation algorithms. Being result driven I have a passion for facilitating stakeholders to make data driven decisions by quantifying and communicating the impact of interventions to non-specialist audiences in an accessible manner.\r\n\r\nMy claim for fame is that between 2004-2014 I lived in four different continents within a span of a decade, including three tennis Grand Slam cities (NYC, Melbourne, London).", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 142, "guid": "6ed4f7bb-17ed-5fc8-b341-48a52ef1be80", "logo": "", "date": "2022-06-19T13:30:00+01:00", "start": "13:30", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-142-auc-is-worthless-lessons-in-transitioning-from-academic-to-business-data-science", "url": "https://london2022.pydata.org/cfp/talk/QBEFFB/", "title": "AUC is worthless: Lessons in transitioning from academic to business data science", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "New data scientists often struggle to make major impacts on solving business problems despite impressive technical skills. A core challenge is the gap between how academics think about performance of models and what matters for a company. As an example, academic work summarizes a model\u2019s receiver operator characteristic (ROC) curve with the area under the curve (AUC). This summary statistic is useless for business applications, which will always have unique trade-offs and constraints. Effective approaches to optimize model performance requires understanding the specific business requirements and how to map that to a well framed data science problem.\r\n\r\nIn this talk, I will go through a framework of how to think effectively about model trade-offs in terms of maximizing business utility. Through this exercise, we will build intuition for what is required for a model in production to be a success and how to collaborate more effectively with non-technical co-workers.", "description": "As demand for data scientists and machine learning engineers have skyrocketed, there has been an explosion of programs that excel at building the raw technical skills. These programs work through cutting edge research and models, which help top-notch technical skills. But there is all too often a gap in how to apply them in real-world business settings.\r\n\r\nAcademic machine learning research focuses on metrics such as F1 score, accuracy, and area under the ROC curve (AUC). These metrics are great general-use metrics to compare modeling techniques for iconic problems such as how ImageNet classification accuracy has improved over time. A practitioner at a company will face unique trade-offs and constraints, which requires a different way of thinking about model comparisons.\r\n\r\nA useful framework is to quantify the financial benefits and costs for each entry of a confusion matrix. Using this approach, model thresholds can be set to maximize business outcomes. The exercise of going through this simple model will help build intuition around\r\n\r\n- How to map trade-offs between false positive and false negatives into optimization problems\r\n- Why business expenses like customer acquisition costs don\u2019t impact threshold decisions\r\n- How to anticipate necessary acceptance rates even before starting to do any modeling\r\n- When a human-in-the-loop can be valuable\r\n\r\nThe target audience of this talk are people who want to transition or recently have transitioned into data science work for a company, though these ideas can be helpful for experienced data scientists.", "recording_license": "", "do_not_record": false, "persons": [{"id": 94, "code": "Z8S8MU", "public_name": "Dillon Gardner", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 127, "guid": "e3934a93-6988-5b50-a23f-7cb698980e93", "logo": "", "date": "2022-06-19T14:15:00+01:00", "start": "14:15", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-127-building-successful-data-science-projects", "url": "https://london2022.pydata.org/cfp/talk/MKUTFH/", "title": "Building Successful Data Science Projects", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Your data science projects haven't worked out so well - maybe you didn't have a plan, you suffered from surprising unknowns or you couldn't deliver what someone else promised. I'll share both some painful past experiences and explain choices that will increase your success. I'll root this in a recently shipped solution worth $1 million for a client.", "description": "Your data science projects haven't worked out so well - maybe you didn't have a plan, you suffered from surprising unknowns, you couldn't deliver what was promised or you just failed to ship. I've been there over the last 20 years.\r\n\r\nI'll share some painful past experiences and explain how you can avoid these common failures. I've just shipped a solution worth $1 million for a client by following my own advice - you can do the same.\r\n\r\nWe'll talk about estimating the value of your choices, getting written agreement for a project plan, identifying risks and derisking them, validating results with the business, shipping quickly, identifying bottlenecks and iterating our way to success. You'll leave the talk with new ideas to improve the success of your team and your personal career.", "recording_license": "", "do_not_record": false, "persons": [{"id": 38, "code": "TQ7QZY", "public_name": "Ian Ozsvald", "biography": "Ian is a Chief Data Scientist and Coach, he's helped co-organise the annual PyDataLondon conference with 700+ attendees and the associated 11,000+ member monthly meetup. He runs the established Mor Consulting Data Science consultancy in London, gives conference talks internationally often as keynote speaker and is the author of the bestselling O'Reilly book High Performance Python (2nd edition). He has 19 years of experience as a senior data science leader, trainer and team coach. For fun he's walked by his high-energy Springer Spaniel, surfs the Cornish coast and drinks fine coffee. Past talks and articles can be found at: \r\n\r\n* https://ianozsvald.com/\r\n* https://github.com/ianozsvald/\r\n* https://twitter.com/ianozsvald\r\n* https://www.linkedin.com/in/ianozsvald/", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 207, "guid": "c2c225df-25ab-5d29-985d-d31e20d34fd3", "logo": "", "date": "2022-06-19T15:00:00+01:00", "start": "15:00", "duration": "00:45", "room": "Tower Suite 3", "slug": "cfp-207-why-do-i-need-to-know-python-i-m-a-pandas-user-", "url": "https://london2022.pydata.org/cfp/talk/E7VUYU/", "title": "Why do I need to know Python? I'm a pandas user\u2026", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "You use pandas every day. You know every keyword argument on every function, even `.melt`! You even know whether it's `.rename`, `.rename_axis`, or `.set_axis` that you want\u2014and you get it right on the first try! So why bother learning Python? Sure, pandas is written in it, but outside of assembling parts of the pandas API, what's there that has any value in your life?", "description": "It's common for data scientists to narrowly focus on the APIs of the tools they use every day\u2014`pandas`, `matplotlib`, `pymc`, `dask`, &c.\u2014to the detriment of any focus on the surrounding programming language. In the case of tools like `matplotlib`, the total amount of Python we need to know is limited to what existed when `matplotlib` was first developed. (Did you know that `matplotlib` predates `@property`? That explains a lot\u2026) In the case of newer tools like `dask` or `pymc` or even `pandas`, we may encounter some newer parts of Python\u2014e.g., context managers or descriptors\u2014as part of these tools' API design, but it's very easy to accept these as mere \u201csyntax.\u201d\r\nIn this talk, we will discuss where a deeper understanding of pure Python has direct and immediate consequences to your work as a data scientist. We will discuss where these parts of Python you may have skimmed over show up in analytical code, outside of the mere \u201csyntax\u201d of an API.\r\nThis talk will be organised around answering the following questions:\r\n- why do generators even matter (and who cares about coroutines)?\r\n- the `itertools` module is great\u2026 if I were writing scripts, but where does it show up in data analysis?\r\n- object orientation seems like a bunch of bureaucracy\u2014can it really simplify my analytical code?\r\n- why should I bother with data types in the builtins and `collections`; is the `pandas.DataFrame` not enough?\r\n- knowledge of Python internals would probably be useful, if I were a programmer writing scripts, but why do they matter for a data scientist?", "recording_license": "", "do_not_record": false, "persons": [{"id": 130, "code": "FZUBV7", "public_name": "James Powell", "biography": "James Powell serves on the board of NumFOCUS as co-Chairman and Vice President. NumFOCUS is the 501(c)(3) non-profit that supports all the major tools in the Python data analysis ecosystem (incl. pandas, numpy, jupyter, matplotlib, and others.) At NumFOCUS, he helps build global open source communities for data scientists, data engineers, and business analysis. He helps NumFOCUS run the PyData conference series and has sat on speaker selection and organizing committees for over two dozen conferences. James is also a prolific speaker: since 2013, he has given over seventy conference talks at over fifty Python events worldwide.", "answers": []}], "links": [], "attachments": [], "answers": []}], "Beaufort": [{"id": 200, "guid": "4f6da86b-fd52-5bc9-9513-27f9615207aa", "logo": "", "date": "2022-06-19T10:15:00+01:00", "start": "10:15", "duration": "05:30", "room": "Beaufort", "slug": "cfp-200-unconference-track", "url": "https://london2022.pydata.org/cfp/talk/PDGDA9/", "title": "Unconference Track", "subtitle": "", "track": null, "type": "Unconference Track", "language": "en", "abstract": "Informal sessions led by attendees will be running all day Sunday, 19 June in the Beaufort Room. Unconference sessions are facilitated discussions on topics of interest, impromptu hacking sessions on a specific topic/library, anything that is on topic for the conference but falls outside the formal talks/tutorials tracks -- if you'd like to lead a session, propose your idea to the organisers at the registration desk and reserve time on the schedule.", "description": "", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}]}}]}}}